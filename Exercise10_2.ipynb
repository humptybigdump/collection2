{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 10.2: Space Mission Planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T18:41:07.265000+01:00",
     "start_time": "2022-01-10T17:40:20.718Z"
    }
   },
   "outputs": [],
   "source": [
    "include(\"mplstyle.jl\")\n",
    "include(\"optimization_library.jl\")\n",
    "include(\"ad.jl\")\n",
    "include(\"nbody_simulation.jl\")\n",
    "\n",
    "using Distributions\n",
    "import Dates\n",
    "import DelimitedFiles\n",
    "DF = DelimitedFiles;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Planet | Mass | Distance from Sun |\n",
    "| --- | --- | --- |\n",
    "| Sun | 1.989e30 kg | 0 AU |\n",
    "| Earth | 5.972e24 kg | 1 AU |\n",
    "| Mercury | 3.30e23 kg | 0.38 AU |\n",
    "| Mars | 6.4219e23 kg | 1.52 AU |\n",
    "| Venus | 4.869e24 kg | 0.72 AU |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T18:41:16.292000+01:00",
     "start_time": "2022-01-10T17:40:21.637Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = [\"Sun\", \"Mercury\", \"Venus\", \"Earth\", \"Mars\",\"Rocket\"]\n",
    "\n",
    "# Masses of bodies in kg\n",
    "m = [1.989e30, 3.30e23, 4.867e24, 5.972e24, 6.4219e23]\n",
    "\n",
    "# Distance to the sun in m\n",
    "d = [0.00, 0.38, 0.72, 1.00, 1.52] * AU\n",
    "\n",
    "# Speed of bodies in m/s\n",
    "s = [0.00, 47.9, 35.0, 29.8, 24.1] * 1000\n",
    "\n",
    "#startpositions\n",
    "p = [[0,0],[-1,0],[0,1],[1,0],[0,-1]]\n",
    "\n",
    "#velocitydirection\n",
    "v = [[0,0],[0,-1],[-1,0],[0,1],[1,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T18:43:25.111000+01:00",
     "start_time": "2022-01-10T17:40:21.902Z"
    }
   },
   "outputs": [],
   "source": [
    "B = [Body(d[i]*p[i], s[i]*v[i], m[i], [0.0,0.0]) for i=1:length(m)]\n",
    "\n",
    "Δt = 3600.0 * 10\n",
    "tmax = 2000\n",
    "\n",
    "simulate_n_bodies(B,Δt, tmax, \"solar_system\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T18:45:13.495000+01:00",
     "start_time": "2022-01-10T17:40:22.269Z"
    }
   },
   "outputs": [],
   "source": [
    "# Do a simulation including the rocket\n",
    "B = [Body(d[i]*p[i], s[i]*v[i], m[i], [0.0,0.0]) for i=1:length(m)]\n",
    "\n",
    "theta = [10000.0, 1000.0]\n",
    "\n",
    "# The rocket starts at earth's position and speed plus some offset\n",
    "push!(B, Body(B[4].pos + ones(2) * 0.01*AU, B[4].speed + theta, 5.0 * 10^4, [0.0,0.0]))\n",
    "simulate_n_bodies(B,Δt, tmax, \"solar_system_with_rocket\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Problem\n",
    "\n",
    "The loss function is given by:\n",
    "\n",
    "\\begin{align*}\n",
    "l(\\theta) = \\| \\vec r_{\\mathrm{Mars}}^{(k)} - \\vec r_{\\mathrm{Rocket}}^{(k)} \\|^2 + \\| \\vec r_{\\mathrm{Earth}}^{(l)} - \\vec r_{\\mathrm{Probe}}^{(l)} \\|^2,\\qquad \\mathrm{with}\\; l>k\n",
    "\\end{align*}\n",
    "with $\\theta$ the initial speed vector of the rocket that is added to the speed vector of earth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T18:45:15.013000+01:00",
     "start_time": "2022-01-10T17:40:23.152Z"
    }
   },
   "outputs": [],
   "source": [
    "function trajectory_loss(theta::Vector{T}) where T\n",
    "    B = [Body{T}(d[i]*p[i], s[i]*v[i], m[i], [0.0,0.0]) for i=1:length(m)]\n",
    "    \n",
    "    # The rocket starts at earth's position and speed plus some offset\n",
    "    push!(B, Body{T}(B[4].pos + ones(2) * 0.01*AU, B[4].speed + theta, 5.0 * 10^4, [0.0,0.0]))\n",
    "    \n",
    "    dist_mars = zeros(T, tmax)\n",
    "    dist_earth = zeros(T, tmax)\n",
    "    for t=1:tmax\n",
    "        simulate_step!(B, Δt,t)\n",
    "        dist_mars[t] = norm2(B[5].pos - B[6].pos)\n",
    "        dist_earth[t] = norm2(B[4].pos - B[6].pos)\n",
    "    end\n",
    "    min_mars, idx = findmin(dist_mars)\n",
    "    min_earth = minimum(dist_earth[idx:end])\n",
    "    return min_mars + min_earth\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function topologie\n",
    "\n",
    "To get a feeling for the problem we will take a look on the loss in our parameterspace given by $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-500000.0:5025.125628140703:500000.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_points = 200 #The more points, the higher the resolution of the graph. You maybe want to reduce the number of points to reduce runtime\n",
    "θ1_plot = range(-500000,500000,length = n_points)\n",
    "θ2_plot = range(-500000,500000,length = n_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As each loss evaluation implies a simulation, computing the data to plot the loss topologie might take a while, therefore lets save the data just in case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DelimitedFiles\n",
    "losses_plot = [trajectory_loss([θ1,θ2]) for θ1 = θ1_plot, θ2 = θ2_plot]\n",
    "writedlm( \"loss_plot_lecture_problem.csv\",  losses_plot, ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your notebook kernel dies or you computed the values in the past, just load in the results from last time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DelimitedFiles\n",
    "losses_plot = readdlm(\"loss_plot.csv\",',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T18:45:29.603000+01:00",
     "start_time": "2022-01-10T17:40:23.816Z"
    }
   },
   "outputs": [],
   "source": [
    "#plotting\n",
    "# create grid points\n",
    "xgrid = repeat(θ1_plot',n_points,1)\n",
    "ygrid = repeat(θ2_plot,1,n_points);\n",
    "\n",
    "fontsize = 13\n",
    "\n",
    "using3D()\n",
    "pygui(true);\n",
    "fig = figure(\"pyplot_surfaceplot\",figsize=(15,10))\n",
    "ax = fig.add_subplot(1,1,1,projection=\"3d\")\n",
    "plot_surface(xgrid', ygrid', losses_plot, rstride=2,\n",
    "             edgecolors=\"k\", cstride=2, cmap=ColorMap(\"jet\"), alpha=0.3, linewidth=0.25)\n",
    "PyPlot.zscale(\"log\")\n",
    "xlabel(L\"\\theta_1\", fontsize=fontsize)\n",
    "ylabel(L\"\\theta_2\", fontsize=fontsize)\n",
    "zlabel(L\"loss\", fontsize=fontsize)\n",
    "#show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T18:31:08.192000+01:00",
     "start_time": "2022-01-10T17:25:38.038Z"
    }
   },
   "outputs": [],
   "source": [
    "# ========================================================================================\n",
    "# Define the gradient function of trajectory_loss() using the provided methods in ad.jl\n",
    "# ========================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T18:31:08.194000+01:00",
     "start_time": "2022-01-10T17:25:38.293Z"
    }
   },
   "outputs": [],
   "source": [
    "# ===========================================================================\n",
    "# Minimize the loss function using the gradient_descent function from optimization_library.jl\n",
    "# Hint: Since the loss function is not convex, there is no guarantee that you found the global minimum. However, \n",
    "# sometimes a \"more optimal\" solution than the starting point is already sufficient.\n",
    "# Run the simulation using your optimal solution. Do you reach Mars and come back to earth within the simulation time?\n",
    "# We found the minimum in our tests for [-15073.550552647714, -55121.971458839835], if you find a better solution let us know ;D\n",
    "# ==========================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 10.3: Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T18:46:36.904000+01:00",
     "start_time": "2022-01-10T17:46:36.898Z"
    }
   },
   "outputs": [],
   "source": [
    "using MLDatasets\n",
    "using Images\n",
    "using ReverseDiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T18:46:38.848000+01:00",
     "start_time": "2022-01-10T17:46:37.242Z"
    }
   },
   "outputs": [],
   "source": [
    "train_x, train_y = MNIST.traindata()\n",
    "test_x,  test_y  = MNIST.testdata();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T18:47:13.758000+01:00",
     "start_time": "2022-01-10T17:46:37.534Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the k-th image\n",
    "k = 19\n",
    "println(train_y[k])\n",
    "Plots.plot(Gray.(train_x[:,:,k]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T18:47:14.041000+01:00",
     "start_time": "2022-01-10T17:46:41.515Z"
    }
   },
   "outputs": [],
   "source": [
    "# define the sigmoid activation function\n",
    "sigmoid(z) = 1.0 / (1.0 + exp(-z))\n",
    "\n",
    "# define the softmax function\n",
    "function softmax(z)\n",
    "    res = exp.(z .- maximum(z))\n",
    "    return res / sum(res)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T18:32:43.621000+01:00",
     "start_time": "2022-01-10T17:25:39.527Z"
    }
   },
   "outputs": [],
   "source": [
    "# The input is a 28x28 matrix\n",
    "# The output is a 10-vector\n",
    "function classify_mnist(theta, im)    \n",
    "    W1 = reshape(theta[1:100352], (128,28*28))\n",
    "    b1 = theta[100353:100480]\n",
    "    layer1(x) = sigmoid.(W1 * x + b1)\n",
    "    \n",
    "    W3 = reshape(theta[100481:101760], (10,128))\n",
    "    b3 = theta[101761:101770]\n",
    "    layer2(x) = softmax(W3 * x + b3)\n",
    "    \n",
    "    return layer2(layer1(vec(im)))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T18:32:43.839000+01:00",
     "start_time": "2022-01-10T17:25:39.727Z"
    }
   },
   "outputs": [],
   "source": [
    "training_cycles = 10^3; \n",
    "learning_rate = 0.1;\n",
    "batchsize = 128\n",
    "\n",
    "function loss_minibatch(theta)\n",
    "    loss = 0.0\n",
    "    for i=1:batchsize\n",
    "        n = rand(1:length(train_y))\n",
    "        res = classify_mnist(theta, train_x[:,:,n])\n",
    "        loss += -log(res[train_y[n]+1])\n",
    "    end\n",
    "    return loss\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T18:32:44.035000+01:00",
     "start_time": "2022-01-10T17:25:40.231Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the gradient function of loss_minibatch by using Reverse Mode AD\n",
    "grad_loss_minibatch(theta) = ReverseDiff.gradient(loss_minibatch, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T18:32:44.047000+01:00",
     "start_time": "2022-01-10T17:25:40.917Z"
    }
   },
   "outputs": [],
   "source": [
    "# ADAM is an improved Gradient Descent for Neural Networks\n",
    "# Kingma, D. P., & Ba, J. (2014). Adam: A method for stochastic optimization.\n",
    "function adam!(df, θ; iters=1000, α=0.001, β1 = 0.9, β2=0.999, ϵ=10.0^(-8))\n",
    "    m = zeros(size(θ))\n",
    "    v = zeros(size(θ))\n",
    "    mhat = zeros(size(θ))\n",
    "    vhat = zeros(size(θ))\n",
    "    for t=1:iters\n",
    "        print(\".\")\n",
    "        g = df(θ)\n",
    "        m[:] = β1 * m[:] + (1-β1) * g[:]\n",
    "        v[:] = β2 * v[:] + (1-β2) * g[:].^2\n",
    "        mhat[:] = m / (1-β1^t)\n",
    "        vhat[:] = v / (1-β2^t)\n",
    "        θ[:] = θ[:] .- (α * mhat ./ (sqrt.(vhat) .+ ϵ)) \n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T18:37:22.412000+01:00",
     "start_time": "2022-01-10T17:25:41.598Z"
    }
   },
   "outputs": [],
   "source": [
    "# start with zero for the model parameters\n",
    "# otherwise the first sigmoid layer will be \"all zeros\"\n",
    "theta = rand(101770);\n",
    "\n",
    "# train\n",
    "adam!(grad_loss_minibatch, theta, iters=500, α=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T18:37:22.584000+01:00",
     "start_time": "2022-01-10T17:25:42.127Z"
    }
   },
   "outputs": [],
   "source": [
    "# write into file\n",
    "DF.writedlm(\"theta.csv\", theta, ',');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T18:37:23.883000+01:00",
     "start_time": "2022-01-10T17:25:42.924Z"
    }
   },
   "outputs": [],
   "source": [
    "# read from file as a shortcut\n",
    "theta2 = DF.readdlm(\"theta.csv\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T18:37:25.078000+01:00",
     "start_time": "2022-01-10T17:25:44.040Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the k-th image\n",
    "k = rand(1:length(test_y))\n",
    "res = classify_mnist(theta2, test_x[:,:,k])\n",
    "println(\"Selected Sample: \", k)\n",
    "println(\"Prediction Distribution: \", res)\n",
    "println(\"Predicted Category: \", argmax(res)-1)\n",
    "Plots.plot(Gray.(test_x[:,:,k]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.3",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
