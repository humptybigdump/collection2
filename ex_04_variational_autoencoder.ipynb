{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "46c4184033624f4f8ba489f0e0c076f0",
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cd8c48bceae4fb6085d02c7f6e58a8dc",
     "grade": false,
     "grade_id": "cell-0cb281c509045a83",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Grundlagen der Künstlichen Intelligenz - Wintersemester 2024/25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b9cad96faf594a51a780631ec3bb48f6",
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "52fa7afb5a6f50b293f5fa7bda97e84c",
     "grade": false,
     "grade_id": "cell-c2fe58a0253377de",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Übung 4: Variational Autoencoder\n",
    "\n",
    "---\n",
    "\n",
    "> 'Grundlagen der künstlichen Intelligenz' im Wintersemester 2024/2025\n",
    ">\n",
    "> - T.T.-Prof. Benjamin Schäfer, benjamin.schaefer@kit.edu\n",
    "> - Prof. Gerhard Neumann, gerhard.neumann@kit.edu\n",
    "\n",
    "---\n",
    "\n",
    "In dieser Übung werden wir einen VariationalAutoencoder trainieren und verschiedene Anwendungsfälle betrachten. Wir werden in dieser Übung zum ersten Mal mit der Bibliothek PyTorch arbeiten. Schaut Euch dazu auch das folgende Einstiegstutorial an: https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html, sowie das Pytorch Tutorial aus der Übung vom 06.12.24. Bei den jeweiligen Aufgaben findet Ihr weiter unten auch noch die relevanten Links zu spezifischer Dokumentation.\n",
    "\n",
    "**Bitte verändert den Code nicht so, dass er auf der GPU läuft. Alle Aufgaben können ohne Probleme auf der CPU gelöst werden.**\n",
    "\n",
    "\n",
    "### Übungsteam\n",
    "\n",
    "- Sebastian Pütz, sebastian.puetz@kit.edu\n",
    "- Ulrich Oberhofer, ulrich.oberhofer@kit.edu\n",
    "- Philipp Dahlinger, philipp.dahlinger@kit.edu\n",
    "- Nicolas Schreiber, nicolas.schreiber@kit.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "6363fe99609e41d1a8b76883ed18b3c8",
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "585f5c1e44851c56851461b69a354c5d",
     "grade": false,
     "grade_id": "cell-74059acf30582754",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Gruppenabgabe\n",
    "\n",
    "Die Übungsblätter können in Gruppen von bis zu **3 Studierenden** abgegeben werden. **Jede Person aus der Gruppe muss die finale Version der Abgabe über Ilias hochladen**, es genügt nicht, dass nur eine Person aus der Gruppe dies tut. Es ist prinzipiell möglich, im Laufe des Semesters sich einer neuen Gruppe anzuschließen, sollte sich die eigene Gruppe vorzeitig auflösen. Generell muss jede Gruppe ihre eigene Lösung hochladen, wir werden die Abgaben auf Duplikate überprüfen.\n",
    "\n",
    "Die Gruppen werden automatisch erfasst, **gebt deshalb die u-Kürzel eurer Gruppenmitglieder in die folgende Zelle ein.** Falls eure Gruppe nur aus 2 Studierenden besteht, oder ihr alleine abgibt, lasst die verbleibenden Felder frei. Hier ein Beispiel für eine Gruppe bestehend aus uabcd und uefgh:\n",
    "\n",
    "_U-Kürzel der Gruppenmitglieder:_\n",
    "\n",
    "_Mitglied 1: uabcd_\n",
    "\n",
    "_Mitglied 2: uefgh_\n",
    "\n",
    "_Mitglied 3:_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a448c5abd1c746b6924905d50b3c2611",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "U-Kürzel der Gruppenmitglieder:\n",
    "\n",
    "Mitglied 1:\n",
    "\n",
    "Mitglied 2:\n",
    "\n",
    "Mitglied 3:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b3c7e56cccca4894845a14c6688972b3",
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7a418cfcb966160fdb4d60050b50331b",
     "grade": false,
     "grade_id": "cell-d261c284cf5b2236",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Auto-grading\n",
    "\n",
    "Wir nutzen ein auto-grading System, welches eure abgegebenen Jupyter Notebooks automatisch analysiert und über\n",
    "hidden Tests auf Richtigkeit prüft. Über diese Tests werden die Punkte bestimmt, die ihr für das Übungsblatt erhaltet.\n",
    "\n",
    "Damit das auto-grading reibungslos funktioniert bitte folgende Dinge beachten:\n",
    "\n",
    "- Vor dem Abgeben eines Notebooks bitte testen, dass alles von vorne bis hinten ohne Fehler durchläuft.\n",
    "- Zellen, welche mit \"### DO NOT CHANGE ###\" markiert sind dürfen weder gelöscht noch bearbeitet werden\n",
    "- Eure Lösung muss in die richtige Zelle (markiert mit \"# YOUR CODE HERE\") eingetragen werden.\n",
    "    - (dabei natürlich den NotImplementedError löschen!)\n",
    "- Es gibt potentiell scheinbar leere Zellen, die auch mit \"### DO NOT CHANGE ###\" markiert sind. Auch diese dürfen nicht bearbeitet oder gelöscht werden.\n",
    "    - Falls dies doch gemacht wird, dann wird das automatische Grading nicht funktionieren und ihr erhaltet keine Punkte.\n",
    "    - Wir werden hier strikt handeln und keine Ausnahmen machen, falls jemand doch Zellen verändert, die eindeutig als readonly markiert sind!\n",
    "- Die Jupyter Notebooks haben inline Tests (für euch sichtbar), welche euer Ergebnis auf grobe Richtigkeit überprüfen.\n",
    "    - Diese sind primär für euch, um Fehler zu erkennen und zu korrigieren.\n",
    "    - Die inline Tests, die ihr im Notebook sehen könnt, sind allerdings nicht die Tests welche für das Grading verwendet werden!\n",
    "    - Die inline Tests sind eine notwendige Bedingung, um beim Grading der Aufgabe Punkte zu erhalten!\n",
    "\n",
    "# **WICHTIG** Abgabe des Notebooks\n",
    "- Bitte das Jupyter Notebook mit dem ursprünglichen Dateinamen ins Ilias hochladen (\"ex_03_neural_networks.ipynb\")\n",
    "- Bitte Jupyter Notebook und handgeschriebene PDF einzeln hochladen, nicht als ZIP.\n",
    "- Bitte darauf achten, dass die Jupyter Notebook Zell-Metadaten erhalten bleiben. Das ist eigentlich immer der Fall,\n",
    "in wenigen Fällen gab es hier jedoch Probleme. Um auf Nummer Sicher zu gehen bitte das Notebook vor der Abgabe ein Mal\n",
    "in einem normalen Texteditor öffnen und nach \"nbgrader\" suchen. Wenn hier dann keine entsprechenden JSON-Einträge auftauchen\n",
    "dann sind leider die Metadaten verloren gegangen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8384507209814356a3b8a49e4a738b1a",
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9c5b0548524b665481f95425fb05e981",
     "grade": false,
     "grade_id": "cell-c038269aeb92c6b7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Teil 1: Implementierung und Training des Variational Autoencoders\n",
    "\n",
    "Im ersten Teil dieser Übung implementieren und trainieren wir einen Variational Autoencoder. Ein Variational Autoencoder ist eine Subform des Autoencoders: Autoencoder bestehen aus einem Encoder- und einem Decoder-Netzwerk. Das Encoder-Netzwerk generiert dabei eine komprimierte, niederdimensionale Repräsentation des Inputs, der sogenannte Latent Space. Diese wird dann durch das Decoder Netzwerk wieder in eine Ausgabe transformiert, die die gleichen Dimensionen wie der ursprüngliche Input aufweist. Bei einem Variational Autoencoder besteht der Latent Space aus der Repräsentation des Mittelwerts und der Standardabeichung einer Normalverteilung, aus dieser dann mithilfe eines Reparametrisierungstricks ein Sample der Normalverteilung gebildet wird.\n",
    "#### Autoencoder\n",
    "![autoencoder.png](autoencoder.png)\n",
    "#### Variational Autoencoder\n",
    "![VAE.png](VAE.png)\n",
    "\n",
    "\n",
    "Als erstes müssen wir wieder den Datensatz einlesen und verwenden dafür die Klasse `Dataset` aus `torch.utils`. Anschließend nutzen wir die (effiziente) Implementierung der `Dataloader` Klasse zur Iteration über Minibatches.\n",
    "\n",
    "Beachtet während des ganzen Notebooks, dass PyTorch mit Daten im Format `torch.Tensor` arbeitet (anstelle von `numpy.array`). Beide Datenformate können aber einfach ineinander umgewandelt werden. Ihr findet an den entsprechenden Stellen im Verlauf des Notebooks die nötigen weiteren Informationen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "d75d9c960afe45f6b68f79cdbb94f6af",
    "deepnote_cell_type": "code",
    "deletable": false,
    "editable": false,
    "execution_context_id": "e61cec99-06a1-4ae2-99a0-8e65cc71dbae",
    "execution_millis": 946,
    "execution_start": 1733730893661,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7160dd0fc656039bd3bec565c0d344bd",
     "grade": false,
     "grade_id": "cell-673766003a23acf5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "57a2a0f4"
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "# imports\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from functools import reduce\n",
    "from operator import mul\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "7f566cdde4b74a4db9ac7d45e142ce2a",
    "deepnote_cell_type": "code",
    "deletable": false,
    "editable": false,
    "execution_context_id": "e61cec99-06a1-4ae2-99a0-8e65cc71dbae",
    "execution_millis": 2332,
    "execution_start": 1733730894660,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "81e1c5ef5be8bae0895771967aab2361",
     "grade": false,
     "grade_id": "cell-e6813fbb54e4ccc7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "87a2572c"
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.squeeze(0))  # Remove the single channel dimension\n",
    "])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root='./', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./', train=False, transform=transform, download=True)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4014bc2388ef445e980d0c93a38388e8",
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b7beec319d45a4de3815d5e9e34f268c",
     "grade": false,
     "grade_id": "cell-de5d3091e850f1ea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Als nächstes definieren wir eine Funktion zum Visualisieren der einzelnen Bilder und lassen uns jeweils die ersten\n",
    "10 Bilder aus dem Trainings- und Testdatensatz anzeigen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "1aedd41a734a42229e9163136ec3a017",
    "deepnote_cell_type": "code",
    "deletable": false,
    "editable": false,
    "execution_context_id": "e61cec99-06a1-4ae2-99a0-8e65cc71dbae",
    "execution_millis": 1025,
    "execution_start": 1733730897056,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c9851c82144952025c82af784d305a04",
     "grade": false,
     "grade_id": "cell-6a40b0fd35c222a6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "3224713e"
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "def visualize_data(batch_of_imgs):\n",
    "    \"\"\"\n",
    "    batch_of_imgs: Sequence of two-dimensional torch.tensors\n",
    "    return: None\n",
    "    \"\"\"\n",
    "    num_imgs = len(batch_of_imgs)\n",
    "    fig, ax = plt.subplots(1, num_imgs)\n",
    "    if num_imgs == 1:\n",
    "        # matplotlib does not create a list of axes when there is only 1 subplot created. To obtain the same\n",
    "        # interface, we wrap it in a list.\n",
    "        ax = [ax]\n",
    "    wspace = 0.2\n",
    "    fig.set_figwidth((0.6+wspace)*num_imgs-wspace)\n",
    "    plt.subplots_adjust(left=0.0, bottom=0.0, right=1.2, top=1.0, wspace=wspace, hspace=0.1)\n",
    "    for i in range(num_imgs):\n",
    "        ax[i].imshow(1 - batch_of_imgs[i], cmap='gray')\n",
    "        ax[i].set_xticks([])\n",
    "        ax[i].set_yticks([])\n",
    "    plt.show()\n",
    "    \n",
    "print(\"Train data examples:\")\n",
    "visualize_data([train_dataset[i][0] for i in range(10)])\n",
    "print(\"Test data examples:\")\n",
    "visualize_data([test_dataset[i][0] for i in range(10)])\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "3642b79ce3984a08b7d09bd1fe152147",
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "32bdef1b925cec03c3c736b577742674",
     "grade": false,
     "grade_id": "cell-e4fe21a96ea8a5eb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Aufgabe 3.1 - Loss (1 + 1 Punkt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c9a4d98f97104bf18d46f8c92a33b1c0",
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7d85cb4b01584a9069202cf71516806b",
     "grade": false,
     "grade_id": "cell-50b74ad66b7c374c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Die Verlustfunktion/Loss ergibt sich aus der Variational Lower Bound, die es zu maximieren gilt (siehe VL 8, Folien 25 und 37): \n",
    "$$\n",
    "     L( q,  \\theta) = \\sum_{i=1}^N \\Big ( \\mathbb E_{ z_i \\sim q_{ \\phi}( z_i| x_i)},\n",
    " \\left [\\log (p_\\theta( x_i |  z_i) p( z_i)) \\right ] - \\mathbb E_{ z_i \\sim q_{ \\phi}( z_i| x_i)}\\left [ \\log q_{ \\phi}( z_i |  x_i)\\right ] \\Big ).\n",
    " $$\n",
    "In Aufgabe 4.1 zeigt ihr, dass wir die Variational Lower Bound umformen können zu \n",
    "\\begin{align}\n",
    " L( q,  \\theta) = \\sum_{i=1}^N \\Big (\\mathbb E_{ z_i \\sim q_{ \\phi}( z_i| x_i)} \\left [ \\log p_{ \\theta}( x_i |  z_i)\\right ] - \\mathbb E_{ z_i \\sim q_{ \\phi}( z_i| x_i)} \\left [ \\log q_{ \\phi}( z_i |  x_i) - \\log p( z_i) \\right ] \\Big ). \\tag{1}\n",
    "\\end{align}\n",
    " Wir teilen das objective in die beiden Terme in der Summe auf, und erhalten den Reconstruktionsfehler/ Reconstuction loss $\\mathbb E_{ z_i \\sim q_{ \\phi}( z_i| x_i)} \\left [ \\log p_{ \\theta}( x_i |  z_i)\\right ]$ sowie die sogenannte Kullback-Leibler-Divergenz $  \\mathbb E_{ z_i \\sim q_{ \\phi}( z_i| x_i)} \\left [ \\log q_{ \\phi}( z_i |  x_i) - \\log p({z_i}) \\right ]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1de0ecf086cf5456b5f73de666d72891",
     "grade": false,
     "grade_id": "cell-c6d0e2f269b3acce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**a) Rekonstruktionsfehler:** Der Rekonstruktionsfehler ist der erste Summand der umgeformten Variational Lower Bound (1). Wir konstruieren die Wahrscheinlichkeit $p(x|z)$ als Normalverteilung, als Rekonstruktionsfehler ergibt sich daher der Log-Likelihood-Loss und dementsprechend der MSE zwischen der Rekonstruktion und dem Input: <lr>\n",
    "Wir betrachten die Verteilung $p_{\\theta}( x_i |  z_i)$ als Normalverteilung mit konstanter Standardabweichung: $p_{\\theta}( x_i |  z_i) = {N}( x_i |  \\mu_{ \\theta}( z_i), \\sigma)$, wir betrachten also ${\\hat{x}_i} = \\mu_\\theta (z_i)$ als Output des Variational Autoencoders. Wir können den Log-Likelihood-Loss in den MSE-Loss umwandeln; :\n",
    "$$\\log p_{{\\theta}}({x}_i | {z}_i) = -\\frac{1}{2\\sigma^2} \\|{x}_i - {\\mu}_{{\\theta}}({z}_i)\\|^2 - \\frac{d}{2} \\log(2\\pi\\sigma^2)$$\n",
    "Der zweite Term, $-\\frac{d}{2} \\log(2\\pi\\sigma^2)$ ist konstant in Bezug auf die Optimierungsparameter ${\\theta}$ und hat keinen Einfluss auf die Gradienten während des Trainings. Wir erhalten\n",
    "$$\n",
    "\\mathbb{E}_{{z}_i \\sim q_{{\\phi}}({z}_i|{x}_i)} \\left [ \\log p_{{\\theta}}({x}_i | {z}_i)\\right ] \\propto -\\frac{1}{2\\sigma^2} \\mathbb{E}_{{z}_i \\sim q_{{\\phi}}({z}_i|{x}_i)} \\left[ \\|{x}_i - {\\mu}_{{\\theta}}({z}_i)\\|^2 \\right]\n",
    "$$\n",
    "In der Praxis approximieren wir den Erwartungswert pro Datensample ${x_i}$ aus unserem Datensatz durch ein einzelnes sampling von $z_i$ aus $q_{{\\phi}}({z}_i|{x}_i)$.\n",
    "Somit beschreiben wir den zu minimierenden Rekonstruktionsfehler (für jedes Sample i) durch:\n",
    "$\\|{x}_i - {\\mu}_{{\\theta}}({z}_i)\\|^2 = \\|{x}_i - {\\hat{x}_i}\\|^2$.<lr> Jetzt könnt ihr den Rekonstruktionsfehler selbst implementieren.\n",
    "Summiert dazu den Error $\\|{x}_i - {\\hat{x}_i}\\|^2$ über die geflattende Dimension (Beispiel für flatten: Aus Dimensionen (28,28) wird Dimension 28*28) des einzelnen Input-Samples auf, und nehmt anschließend den Durchschnitt über die gesamte Batch mit Batchgröße $B$:\n",
    "$$\n",
    "\\text{Reconstruction Loss} = \\frac{1}{B} \\sum_{i=1}^B \\sum_{j=1}^{d} ({x}_{i,j} - {\\hat{x}}_{i,j})^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "b7881e3f41764b81a51db381a2c9720e",
    "deepnote_cell_type": "code",
    "deletable": false,
    "execution_context_id": "e61cec99-06a1-4ae2-99a0-8e65cc71dbae",
    "execution_millis": 8,
    "execution_start": 1733732270567,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f31369e5cd556c76d73a57f7a1c09ad",
     "grade": false,
     "grade_id": "recon_loss",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "source_hash": "877a5a4"
   },
   "outputs": [],
   "source": [
    "def reconstruction_loss(x: torch.Tensor, x_recon: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Computes the reconstruction loss between the data tensor `x` and the reconstructed tensor `x_recon`\n",
    "    Args:\n",
    "    x (torch.Tensor): Original data tensor. Shape: (batch_size, *data_dims)\n",
    "    x_recon (torch.Tensor): Reconstructed tensor. Shape: (batch_size, *data_dims)\n",
    "    Returns:\n",
    "    The reconstruction loss for the batch\n",
    "    \"\"\"\n",
    "    x_flat= x.flatten(start_dim=1)\n",
    "    x_recon_flat = x_recon.flatten(start_dim=1)\n",
    "    loss = None\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return loss.mean() #return the average loss over the batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7f31273aba1f56800346a7eca1c8006b",
     "grade": false,
     "grade_id": "cell-778423a51e821ba1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**b) Kullback-Leibler-Divergenz (KL-Divergenz):** Allgemein ist für 2 diskrete Wahrscheinlichkeitsverteilungen $Q,P$ auf einer Menge $X$ mit Wahrscheinlichkeitsfunktionen $q,p$ die Kullback-Leibler-Divergenz für $Q$ und $P$ gegeben als $D(Q\\|P) = KL(Q\\|P) = \\sum_{x \\in X}q(x)\\log \\left ( \\frac{q(x)}{p(x)} \\right )$. Wir sehen, dass der zweite Term aus Gleichung (1), $\\mathbb E_{ z_i \\sim q_{ \\phi}( z_i| x_i)} \\left [ \\log q_{ \\phi}( z_i |  x_i) - \\log p( z_i) \\right ]$, genau der KL-Divergenz zwischen den Verteilungen $q_{ \\phi}( z_i |  x_i)$ und $p( z_i)$ entspricht. Da dieser Erwartungswert ein negatives Vorzeichen in der Variational Lower Bound hat, wollen wir ihn entsprechend minimieren. Wir diesen Teil der Loss-Funktion im Folgenden aus als Kullback-Leibler-Loss. <lr>\n",
    "In Aufgabe 4.1 zeigt ihr, dass für Normalverteilungen<lr>\n",
    "$$\n",
    "q(z) = {N}(z|\\mu, \\sigma^2), \\qquad p(z) = {N}(z|0, 1)\n",
    "$$\n",
    " folgende Umformung gilt:\n",
    "$$\n",
    "    \\mathbb E_{ z_i \\sim q_{ \\phi}( z_i| x_i)} \\left [ \\log q_{ \\phi}( z_i |  x_i) - \\log p( z_i) \\right ]  = \\sum_{j=1}^d \\mathbb E_{z_j \\sim q_j(z_j)} \\left [ \\log q_j(z_j) - \\log p_j(z_j) \\right ] \n",
    "    = -\\frac{1}{2} \\sum_{j = 1}^d \\big(1 + \\log(\\sigma_j^2) - \\mu_j^2 - \\sigma_j^2\\big)\n",
    "$$\n",
    "In unserem Fall entspricht $d$ der Dmension des Latent Space. Anschließend wird der Mittelwert über die gesamte Batch berechnet. Implementiert im Folgenden den Kullback-Leibler-Loss auf diese Weise:\n",
    "$$\n",
    "\\text{KL Loss} = \\frac{1}{B} \\sum_{i=1}^B \\left( -\\frac{1}{2} \\sum_{j = 1}^d \\big(1 + \\log(\\sigma_{i,j}^2) - \\mu_{i,j}^2 - \\sigma_{i,j}^2\\big) \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "6322acc811714e30aa3e4895537146ff",
    "deepnote_cell_type": "code",
    "deletable": false,
    "execution_context_id": "e61cec99-06a1-4ae2-99a0-8e65cc71dbae",
    "execution_millis": 1,
    "execution_start": 1733732274107,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd9450c05cd9fe059047f58b7e21cc91",
     "grade": false,
     "grade_id": "kl-task",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "source_hash": "bf5f8455"
   },
   "outputs": [],
   "source": [
    "def gaussian_kullback_leibler(mu_q: torch.Tensor, sigma_q: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Computes the KL divergence between a Gaussian distribution q \n",
    "    (with mean `mu_q` and standard deviation `sigma_q`) and a standard Gaussian distribution p.\n",
    "    Args:\n",
    "    mu_q (torch.Tensor): Mean of the Gaussian distribution q. Shape: (batch_size, latent_dims)\n",
    "    sigma_q (torch.Tensor): Standard deviation of the Gaussian distribution q. Shape: (batch_size, latent_dims)\n",
    "    Returns:\n",
    "    The scalar KL divergence\n",
    "    \"\"\"\n",
    "    kl = None\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return kl.mean() #return the KL divergence averaged over the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "37e2585dff0e4e819c28c1c2c290a93c",
    "deepnote_cell_type": "code",
    "deletable": false,
    "editable": false,
    "execution_context_id": "e61cec99-06a1-4ae2-99a0-8e65cc71dbae",
    "execution_millis": 0,
    "execution_start": 1733732276028,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd4842a3315b5e541004d16a9cfacffb",
     "grade": true,
     "grade_id": "recon",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "49855976"
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "# ID: recon - possible points: 1\n",
    "\n",
    "# reconstruction loss\n",
    "assert torch.isclose(reconstruction_loss(torch.ones(1, 2, 2), torch.ones(1, 2, 2)), torch.zeros(1)), \"Loss should be zero for perfect reconstruction\"\n",
    "assert reconstruction_loss(torch.zeros(3, 2, 2), torch.ones(3, 2, 2)).item() == 4, \"Wrong reconstruction loss\"\n",
    "\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "0be34792270845ceac0801257f9dbbf7",
    "deepnote_cell_type": "code",
    "deletable": false,
    "editable": false,
    "execution_context_id": "e61cec99-06a1-4ae2-99a0-8e65cc71dbae",
    "execution_millis": 3,
    "execution_start": 1733732278082,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "917c18ee7bd3b4b345da8bc842526ec0",
     "grade": true,
     "grade_id": "kl",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "79691be3"
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "# ID: kl - possible points: 1\n",
    "\n",
    "# KL divergence\n",
    "assert torch.isclose(gaussian_kullback_leibler(torch.zeros(1, 2), torch.ones(1, 2)), torch.zeros(1)), \"KL should be zero for standard normal\"\n",
    "assert gaussian_kullback_leibler(torch.ones(3, 2), torch.ones(3, 2)).item() == 1, \"Wrong KL divergence calculation\"\n",
    "\n",
    "### BEGIN HIDDEN \n",
    "mu_q = torch.tensor([[1.0, 2.0, 3.0],\n",
    "                        [0.5, 0.5, 0.5]])\n",
    "sigma_q = torch.tensor([[1.0, 1.0, 1.0],\n",
    "                        [1.0, 1.0, 1.0]])  # Only mu_q is non-zero\n",
    "kl_correct = (0.5 * torch.sum(mu_q ** 2 + sigma_q ** 2 - torch.log(sigma_q ** 2) - 1, dim=1)).mean()\n",
    "assert torch.isclose(gaussian_kullback_leibler(mu_q, sigma_q), kl_correct)\n",
    "\n",
    "mu_q = torch.zeros(2, 3)\n",
    "sigma_q = torch.tensor([[10.0, 10.0, 10.0],\n",
    "                        [10.0, 10.0, 10.0]])\n",
    "kl_correct = (0.5 * torch.sum(mu_q ** 2 + sigma_q ** 2 - torch.log(sigma_q ** 2) - 1, dim=1)).mean()                        \n",
    "assert torch.isclose(gaussian_kullback_leibler(mu_q, sigma_q), kl_correct)\n",
    "\n",
    "mu_q = torch.zeros(2, 3)\n",
    "sigma_q = torch.tensor([[0.1, 0.1, 0.1],\n",
    "                        [0.1, 0.1, 0.1]])\n",
    "kl_correct = (0.5 * torch.sum(mu_q ** 2 + sigma_q ** 2 - torch.log(sigma_q ** 2) - 1, dim=1)).mean()\n",
    "assert torch.isclose(gaussian_kullback_leibler(mu_q, sigma_q), kl_correct)                    \n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a3862c5fb6a142d2891788cfeda5d266",
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "38a602f6025cf61712ee628aa294bcf2",
     "grade": false,
     "grade_id": "cell-a610309a1f9cd512",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Aufgabe 3.2 - Encoder (3 Punkte)\n",
    "\n",
    "In dieser Aufgabe beginnen wir mit der Implementierung des Variational Autoencoders. Hier implementieren wir den Encoder-Teil eines Variational Autoencoders (VAE). Der Encoder transformiert Eingabedaten in eine latente Repräsentation, die durch eine mehrdimensionale (diagonale) Normalverteilung mit Parametern $\\mu$ (Mittelwert) und $\\sigma$ (Standardabweichung) beschrieben wird.\n",
    "\n",
    "**a) Dynamische Initialisierung der Layerstruktur:** Implementiert die dynamische initialisierung der Layerstruktur des Encodernetzwerkes. Die Struktur ist durch die Dimensionen `input_dims`, `hidden_dims` und `latent_dims` vorgegeben. Verwendet lineare Layer (mit `nn.Linear`) mit ReLu-aktivierungs (mit `nn.ReLu`). Die letzten Layer, die von der letzten verborgenen Dimension (`hidden_dims[-1]`) zu den Parametern $\\mu$ und $\\sigma$ in der latenten Dimension (`latent_dims`) abbilden, sind bereits vorgegeben.  Ihr braucht euch also nur die Layer von `input_dims` zu `hidden_dims` und zwischen den verborgenen Dimensione (`hidden_dims`) zu implementieren. Fügt alle Layer und Aktivierungen in eine Liste namens layers ein. Diese Liste wird anschließend an `torch.nn.Sequential` übergeben, um die Layerstruktur zu erstellen.\n",
    "`torch.nn.Sequential` ist ein Hilfsmittel, das mehrere Module (z. B. Lineare Layer und Aktivierungen) in einer sequentiellen Reihenfolge miteinander verbindet, sodass diese zusammen aufgerufen werden können.\n",
    "\n",
    "**b) Reparametrisierungstrick:** Wir modellieren die latente Repräsentation  $z$  als eine zufällige Variable, die aus einer Verteilung  $q(z|x)$  gesampelt wird. Wir nehmen diese Verteilung als multidimensionale (diagonale) Normalverteilung mit Parametern $\\mu$ (Mittelwert) und $\\sigma$ (Standardabweichung) an:\n",
    "$q(z|x) = {N}(z; \\mu, \\text{diag}(\\sigma^2))$\n",
    "Das Sampling aus einer Verteilung wie  $q(z|x)$  ist nicht differenzierbar, weil es sich um einen stochastischen Prozess handelt, der eine nicht stetige, zufällige Auswahl von Werten beinhaltet. Die Differenzierbarkeit ist eine Grundvoraussetzung für Gradient-basierte Optimierungsverfahren wie Backpropagation. \n",
    "Der Reparametrisierungs-Trick umgeht dieses Problem, indem das Sampling in zwei Schritte aufgeteilt wird. Statt direkt aus $q(z|x)$  zu sampeln, wird zuerst aus einer standardisierten Normalverteilung  $\\epsilon \\sim {N}(0, I)$  gesampelt. Die latente Repräsentation $z$ wird durch die folgende Transformation definiert: \n",
    "$$z = \\mu + \\sigma \\odot \\epsilon$$\n",
    "Hier ist  $\\odot$  das Hadamard-Produkt (elementweise Multiplikation),  $\\mu$  der Mittelwert und  $\\sigma$  die Standardabweichung der Verteilung  $q(z|x)$.\n",
    "Hierbei bleibt der Erwartungswert $\\mathbb{E}_{z\\sim{N}(\\sigma, \\mu)}[f(z)] = \\mathbb{E}_{\\epsilon\\sim{N}(0, I)}[f(\\mu + \\sigma \\odot \\epsilon)]$ unverändert.\n",
    "Durch diesen Reparametrisierungstrick wird so die gradienten-basierte Optimierung mit Backpropagation ermöglicht.\n",
    "\n",
    "Implementiert den Reparametrisierungstrick im Forward-Pass des Encoders. Ihr erhaltet die paramter $\\mu$ und $\\sigma$ durch Anwendung der jeweiligen layer auf den output `x` aus den vorherigen layern. Wendet hierbei `torch.exp` auf die Ausgabe für $\\sigma$ an um sicherzustellen, dass $sigma$ positiv ist. Dann könnt ihr `z` aus $\\mu$, $\\sigma$ und einem Sample $\\epsilon$ aus `self.N` berechnen.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "0f8589e2dbda42cc9fab609e8125a8f5",
    "deepnote_cell_type": "code",
    "deletable": false,
    "execution_context_id": "f7e6c099-c4a7-4fca-93f2-9fa8740aa7b7",
    "execution_millis": 0,
    "execution_start": 1733704117926,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "33af34a458f08c088bd753ade3cf0d9e",
     "grade": false,
     "grade_id": "cell-f3e1c148e69ffeb8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "source_hash": "e18324c0"
   },
   "outputs": [],
   "source": [
    "class VariationalEncoder(nn.Module):        \n",
    "    def __init__(self, latent_dims=2, input_dims=28*28, hidden_dims=(512, 256)):\n",
    "        \"\"\"\n",
    "        A Variational Encoder that maps input data to a latent space characterized by \n",
    "        mean (mu) and standard deviation (sigma).\n",
    "        Args:\n",
    "        latent_dims (int): Number of dimensions in the latent space.\n",
    "        input_dims (int): Number of input features\n",
    "        hidden_dims (tuple): Sizes of hidden layers in the encoder network.\n",
    "        \"\"\"\n",
    "        super(VariationalEncoder, self).__init__()\n",
    "\n",
    "        # Build a sequence of layers dynamically based on hidden_dims\n",
    "        layers = []\n",
    "        dims = [input_dims] + list(hidden_dims) + [latent_dims]\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "        self.encoder_layer = nn.Sequential(*layers)\n",
    "        self.mu_layer = nn.Linear(dims[-2], dims[-1])\n",
    "        self.sigma_layer = nn.Linear(dims[-2], dims[-1])\n",
    "\n",
    "        self.N = torch.distributions.Normal(0, 1) # Standard normal distribution for the reparameterization trick\n",
    "        self.kl = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the Variational Encoder.\n",
    "        Args:\n",
    "        x: Input data\n",
    "        Returns:\n",
    "        z: Latent variable sampled from q\n",
    "        \"\"\"\n",
    "        x = torch.flatten(x, start_dim=1) # Flatten the input (from images to vectors)\n",
    "        x = self.encoder_layer(x)\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "        self.kl = gaussian_kullback_leibler(mu, sigma) # Calculate the KL divergence for regularization\n",
    "\n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "10a931eb996142e388b452788c44bf03",
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "581dbf8c0eb9be080003e0010c1f264a",
     "grade": false,
     "grade_id": "cell-38cae5aefc731ec0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Jetzt folgen ein paar Tests, um die Implementierung des Encoder zu testen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "a413e90c73c44cb899e9b2c634c0a31e",
    "deepnote_cell_type": "code",
    "deletable": false,
    "editable": false,
    "execution_context_id": "f7e6c099-c4a7-4fca-93f2-9fa8740aa7b7",
    "execution_millis": 20,
    "execution_start": 1733705616336,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fd4a265e0bb9a28637f544a4ac53254d",
     "grade": true,
     "grade_id": "encoder-arch-test",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "321ef126"
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "# ID: encoder-arch-test - possible points: 3\n",
    "\n",
    "\n",
    "encoder = VariationalEncoder(latent_dims=2, input_dims=28*28, hidden_dims=(512, 256))\n",
    "assert len(encoder.encoder_layer) == 4, \"Fehlende oder zu viele Linear-Layers.\"\n",
    "layers = list(encoder.encoder_layer)\n",
    "assert isinstance(layers[0], nn.Linear), \"Fehler im ersten Linear-Layer.\"\n",
    "assert isinstance(layers[1], nn.ReLU), \"Fehlendes ReLU nach dem ersten Layer.\"\n",
    "assert isinstance(layers[2], nn.Linear), \"Fehler im zweiten Linear-Layer.\"\n",
    "assert isinstance(layers[3], nn.ReLU), \"Fehlendes ReLU nach dem zweiten Layer.\"\n",
    "encoder_params = sum(param.numel() for param in encoder.parameters())\n",
    "assert encoder_params == 534276\n",
    "\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f4f7ffcc320640e380aec79d448312f5",
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "efa196c2040e2309bde28975b8b864b8",
     "grade": false,
     "grade_id": "cell-35c9ddcb3bfa0b45",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Aufgabe 3.3 - Decoder (1 Punkt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a6df8f04b1574c2ab1e293a43150d0f0",
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ba723ef7fc454bb8a4cc12a7e4fd32f6",
     "grade": false,
     "grade_id": "cell-14ac24edd2988812",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Jetzt implementieren wir den Decoder-Teil eines Variational Autoencoders. Die Aufgabe des Decoders besteht darin, die latente Repräsentation  $z$ , die vom Encoder erzeugt wurde, zurück in einen Tensor mit den gleichen Dimensionen wie die ursprünglichen Eingabedaten zu transformieren.\n",
    "\n",
    "Wie beim Encoder soll die Layerstruktur dynamisch initialisiert werden. Die Struktur des Decoders wird durch die Dimensionen `latent_dims`, `hidden_dims` und `output_dims` definiert. Verwendet wieder lineare Layer (`nn.Linear`). Fügt nach jedem linearen Layer, **außer dem letzten**, eine ReLU-Aktivierung (`nn.ReLU`) hinzu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "b06ac7081d7c49c0b4fec5a57b41048e",
    "deepnote_cell_type": "code",
    "deletable": false,
    "execution_context_id": "f7e6c099-c4a7-4fca-93f2-9fa8740aa7b7",
    "execution_millis": 1,
    "execution_start": 1733704126208,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b19bf164068fb1808ec27866355b0e42",
     "grade": false,
     "grade_id": "cell-f549258c3e8887b1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "source_hash": "280d4f40"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dims=2, hidden_dims=(256, 512), output_dims=(28, 28)):\n",
    "\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        # Calculate the flat output size for the final layer\n",
    "        flat_output_size = torch.prod(torch.tensor(output_dims)).item()\n",
    "\n",
    "        # Build a sequence of layers dynamically based on hidden_dims\n",
    "        layers = []\n",
    "        dims = [latent_dims] + list(hidden_dims) + [flat_output_size]\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "        self.decoder_layer = nn.Sequential(*layers)\n",
    "        self.output_dims = output_dims\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.decoder_layer(x)\n",
    "        # Reshape the output to the original dimensions\n",
    "        return x.view(-1, *self.output_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "a3d8da9cac8d4d9db241ebbf28e7e102",
    "deepnote_cell_type": "code",
    "deletable": false,
    "editable": false,
    "execution_context_id": "92289cc2-300c-4773-a79d-69fd8420fb2f",
    "execution_millis": 1,
    "execution_start": 1733691533011,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aa3fd2521721c8cba25a914e334ad050",
     "grade": true,
     "grade_id": "decoder-arch-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "44e6797b"
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "# ID: decoder-arch-test - possible points: 1\n",
    "\n",
    "decoder = Decoder()\n",
    "assert isinstance(decoder, torch.nn.Module)\n",
    "assert len(decoder.decoder_layer) == 5\n",
    "assert isinstance(decoder.decoder_layer[0], nn.Linear), \"First layer should be a Linear layer\"\n",
    "assert isinstance(decoder.decoder_layer[1], nn.ReLU), \"Second layer should be a ReLU layer\"\n",
    "assert isinstance(decoder.decoder_layer[2], nn.Linear), \"Third layer should be a Linear layer\"\n",
    "assert isinstance(decoder.decoder_layer[3], nn.ReLU), \"Fourth layer should be a ReLU layer\"\n",
    "assert isinstance(decoder.decoder_layer[4], nn.Linear), \"Fifth layer should be a Linear layer\"\n",
    "decoder_params = sum(param.numel() for param in decoder.parameters())\n",
    "assert decoder_params == 534544\n",
    "\n",
    "\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9cc21f32ae554067a5fe86a6ac35e33b",
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7a4ad7b607aff22dc43d68735f4a0748",
     "grade": false,
     "grade_id": "cell-8eebbc01c5ddbd87",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Aufgabe 3.4 - Implementierung des Autoencoders (1 Punkt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a78a93f155764c958b04a0fe6de41cd8",
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e192be5b9810d9be1761accdb9fa5bf6",
     "grade": false,
     "grade_id": "cell-6169eb91348c688f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Jetzt setzen wir aus dem Encoder und Decoder den vollen Autoencoder zusammen. Ergänzt dafür die `forward`-Methode im folgenden neuronalen Netz, indem zuerst der Encoder und danach das Decoder angewendet werden.\n",
    "Implementiert hier den forward pass des Autoencoders. Wendet dazu zuerst den Encoder auf den Input `x` an, um die latente Repräsentation `z` zu erhalten. Anschließend wendet den Decoder auf `z` an, um die Rekonstruktion des inputs `x_hat` zu erhalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "fd378b528a20461aa60f98343b8a4dfe",
    "deepnote_cell_type": "code",
    "deletable": false,
    "execution_context_id": "f7e6c099-c4a7-4fca-93f2-9fa8740aa7b7",
    "execution_millis": 0,
    "execution_start": 1733705196110,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f2ec10d425039c9452fbd80b17a7fec6",
     "grade": false,
     "grade_id": "cell-bc75d29612f6c18b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "source_hash": "e83f329a"
   },
   "outputs": [],
   "source": [
    "class Autoencoder(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A class implementing a Variational Autoencoder (VAE) with separate encoder and decoder modules.\n",
    "    Args:\n",
    "        input_dims (tuple of ints): Original shape of the input data (e.g., (height, width)).\n",
    "        latent_dims (int): Dimensionality of the latent space.\n",
    "        hidden_dims_enc (tuple of int): List defining the number of neurons in each hidden layer of the encoder.\n",
    "        hidden_dims_dec (tuple of int): List defining the number of neurons in each hidden layer of the decoder.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dims, latent_dims, hidden_dims_enc, hidden_dims_dec):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        # Store input dimensions and compute flattened dimension\n",
    "        flattened_dims = reduce(mul, data_dims)  # Flattened size, e.g., 28*28=784\n",
    "        \n",
    "        # Instantiate the encoder\n",
    "        self.encoder = VariationalEncoder(\n",
    "            latent_dims=latent_dims,\n",
    "            input_dims=flattened_dims,  # Pass flattened input size to the encoder\n",
    "            hidden_dims=hidden_dims_enc\n",
    "        )\n",
    "        \n",
    "        # Instantiate the decoder\n",
    "        self.decoder = Decoder(\n",
    "            latent_dims=latent_dims,\n",
    "            hidden_dims=hidden_dims_dec,\n",
    "            output_dims=data_dims  # Pass original input size to the decoder\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defines the forward pass for the autoencoder.\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, *input_dims).\n",
    "        Returns:\n",
    "            torch.Tensor: Reconstructed tensor of shape (batch_size, *input_dims).\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        return x_hat\n",
    "\n",
    "    def encode(self, x):\n",
    "        \"\"\"\n",
    "        Encodes input data into the latent space.\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, *data_dims).\n",
    "        Returns:\n",
    "            torch.Tensor: Latent space representation of shape (batch_size, latent_dims).\n",
    "        \"\"\"\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def decode(self, z):\n",
    "        \"\"\"\n",
    "        Decodes latent space data into the original space.\n",
    "        Args:\n",
    "            z (torch.Tensor): Tensor of shape (batch_size, latent_dims).\n",
    "        Returns:\n",
    "            torch.Tensor: Reconstructed tensor of shape (batch_size, *data_dims).\n",
    "        \"\"\"\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def generate(self, num_samples):\n",
    "        \"\"\"\n",
    "        Generates new data samples from random latent space representations.\n",
    "        Args:\n",
    "            num_samples (int): Number of samples to generate.\n",
    "        Returns:\n",
    "            torch.Tensor: Generated data tensor of shape (num_samples, *data_dims).\n",
    "        \"\"\"\n",
    "        # Sample random latent vectors from standard normal distribution\n",
    "        z = torch.randn(num_samples, self.encoder.latent_dims)\n",
    "        generated_data = self.decode(z)  # Decode latent vectors to data space\n",
    "        return generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "6991da6e0da643c891b2d65357c16ad7",
    "deepnote_cell_type": "code",
    "deletable": false,
    "editable": false,
    "execution_context_id": "f7e6c099-c4a7-4fca-93f2-9fa8740aa7b7",
    "execution_millis": 74,
    "execution_start": 1733705819579,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "710b92ac97ad8686fef52acf2dd28333",
     "grade": true,
     "grade_id": "ae",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "b6baf5b9"
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "# ID: ae - possible points: 1\n",
    "\n",
    "autoencoder = Autoencoder(data_dims=(28,28), hidden_dims_enc=(512, 256), latent_dims=2, hidden_dims_dec=(256, 512))\n",
    "encoder = VariationalEncoder(latent_dims=2, hidden_dims=(512, 256), input_dims=28*28)\n",
    "test = next(iter(test_loader))[0][42:43]\n",
    "decoder = Decoder(latent_dims=2, hidden_dims=(256, 512), output_dims=(28, 28))\n",
    "assert isinstance(autoencoder, torch.nn.Module)\n",
    "assert(len(list(autoencoder.parameters())) == len(list(encoder.parameters())) + len(list(decoder.parameters())))\n",
    "assert autoencoder(test).shape == test.shape\n",
    "assert(decoder(encoder(test)).shape == test.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "69e26cb8314f4330809858b6153d6c80",
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8333b0031ef648d0f99297d6d317087d",
     "grade": false,
     "grade_id": "cell-43635d46f455329a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Training des Autoencoders\n",
    "\n",
    "Jetzt ist alles für das Training des Autoencoders vorbeitet und wir können das Netzwerk trainieren, wie unten vorgegeben. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "9f050b58cf90429f9bc9d9ed0f7cf5dc",
    "deepnote_cell_type": "code",
    "execution_context_id": "92289cc2-300c-4773-a79d-69fd8420fb2f",
    "execution_millis": 0,
    "execution_start": 1733691533155,
    "source_hash": "af0d6022"
   },
   "outputs": [],
   "source": [
    "# helper function which shows the current reconstruction\n",
    "def plot_reconstructions(encoder, decoder, test_data, num_samples=7):\n",
    "    # Select a batch of test data\n",
    "    test_batch = test_data[0][:num_samples, :, :]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Pass test data through encoder and decoder\n",
    "        latent_codes = encoder(test_batch)\n",
    "        reconstructions = decoder(latent_codes)\n",
    "\n",
    "        # Display results\n",
    "        print(\"Original Images:\")\n",
    "        visualize_data(test_batch)\n",
    "        \n",
    "        print(\"\\nReconstructed Images:\")\n",
    "        visualize_data(reconstructions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "419c9e71fdb24dc0b309d212df4db9b3",
    "deepnote_cell_type": "code",
    "execution_context_id": "92289cc2-300c-4773-a79d-69fd8420fb2f",
    "execution_millis": 367418,
    "execution_start": 1733694077012,
    "source_hash": "780931ef"
   },
   "outputs": [],
   "source": [
    "grading_env_var = os.getenv('NBGRADER_EXECUTION', None)\n",
    "is_grading = (grading_env_var == \"autograde\" or grading_env_var == \"validate\")\n",
    "\n",
    "# Falls ihr hier etwas ändert, bitte darauf achten, dass diese If-Abfrage nicht entfernt wird.\n",
    "# Ansonsten wird das auto-grading zu lange dauern und abbrechen.\n",
    "if not is_grading:\n",
    "    torch.manual_seed(42)  # Set seed for reproducibility\n",
    "\n",
    "    # Define an optimizer. This updates the weights depending on the gradient. We are using the Adam optimizer here\n",
    "    # Adam is the de-facto standard optimizer for general neural networks. We use a learning rate of 1e-3.\n",
    "\n",
    "    # Initialize the Autoencoder and optimizer\n",
    "    autoencoder = Autoencoder(data_dims=(28,28), hidden_dims_enc=(512, 256), latent_dims=2, hidden_dims_dec=(256, 512))\n",
    "    optimizer = torch.optim.Adam(autoencoder.parameters(), lr=1e-3) \n",
    "    epochs = 25  # Number of training epochs\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss = 0\n",
    "        test_loss = 0\n",
    "        for batch_idx, (x, _y) in enumerate(train_loader):\n",
    "            # the gradients accumulate, so we need to zero_grad() them every iteration\n",
    "            optimizer.zero_grad()  # Reset gradients\n",
    "            reconstruction = autoencoder(x)  # Forward pass\n",
    "            loss = reconstruction_loss(x, reconstruction) + autoencoder.encoder.kl # Compute loss\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Update weights\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # compute test error, we do not need gradients for that, hence the torch.no_grad() block\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (x, _y) in enumerate(test_loader):\n",
    "                reconstruction = autoencoder(x) # Forward pass\n",
    "                loss = reconstruction_loss(x, reconstruction) + autoencoder.encoder.kl # Compute loss\n",
    "                test_loss += loss.item()\n",
    "            train_loss /= len(train_loader)\n",
    "            test_loss /= len(test_loader)\n",
    "            plot_reconstructions(autoencoder.encoder, autoencoder.decoder, next(iter(test_loader)))\n",
    "            print(f\"Epoch: {epoch + 1}, Train Loss: {train_loss:.5f}, Test Loss: {test_loss:.5f}, Training Time: {(time.time() - start_time):6.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "91cac86890d6465682adf4b9e4f15ffb",
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0efb2912f9ea2f1c87c94f107a503992",
     "grade": false,
     "grade_id": "cell-4eae355fab753420",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Nachdem wir nun das Netzwerk trainiert haben, können wir uns nun den zweidimensionalen Latent Space anzeigen. Wir sehen, wie die Daten im Latent Space nach den Ziffern 0-9 gruppiert sind und näherungsweise radial um den Ursprung verteilt sind. Durch den KL-Term in der Loss-Funktion sind die Datenpunkte im Latent Space näherungsweise normalverteilt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "cc0c135a30a24c789159655c35e72fb0",
    "deepnote_cell_type": "code",
    "execution_context_id": "f7e6c099-c4a7-4fca-93f2-9fa8740aa7b7",
    "execution_millis": 2,
    "execution_start": 1733706554738,
    "source_hash": "d3d47d8d"
   },
   "outputs": [],
   "source": [
    "def plot_latent(autoencoder, data_loader, num_batches=100):\n",
    "\n",
    "    autoencoder.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    all_z = []  # To store latent variables\n",
    "    all_labels = []  # To store corresponding labels\n",
    "\n",
    "    with torch.no_grad():  # No gradients needed\n",
    "        for i, (x, y) in enumerate(data_loader):\n",
    "            if i >= num_batches:\n",
    "                break\n",
    "\n",
    "            # Get latent space representation\n",
    "            z = autoencoder.encoder(x)  # Forward pass through encoder\n",
    "            all_z.append(z)  # Store latent variables\n",
    "            all_labels.append(y)  # Store labels\n",
    "\n",
    "    # Concatenate all latent variables and labels\n",
    "    all_z = torch.cat(all_z, dim=0).numpy()\n",
    "    all_labels = torch.cat(all_labels, dim=0).numpy()\n",
    "\n",
    "    # Plot the latent space\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Create scatter plot\n",
    "    scatter = plt.scatter(all_z[:, 0], all_z[:, 1], c=all_labels, cmap='tab10', alpha=0.7)\n",
    "    \n",
    "    # Customize the colorbar\n",
    "    num_classes = len(np.unique(all_labels))\n",
    "    cbar = plt.colorbar(scatter, ticks=[(num_classes-1)/num_classes/2 + i * (num_classes-1)/num_classes for i in range(num_classes)])  # Set ticks at class boundaries\n",
    "    cbar.ax.set_yticklabels([i for i in range(num_classes)])  # Label each tick\n",
    "    cbar.set_label(\"Class\", rotation=270, labelpad=20)\n",
    "\n",
    "    # Add plot labels and title\n",
    "    plt.xlabel(\"Latent Dimension 1\")\n",
    "    plt.ylabel(\"Latent Dimension 2\")\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "fc12b274839a4329911452a98f536edb",
    "deepnote_cell_type": "code",
    "deletable": false,
    "editable": false,
    "execution_context_id": "f7e6c099-c4a7-4fca-93f2-9fa8740aa7b7",
    "execution_millis": 3222,
    "execution_start": 1733706556878,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e17e988526cc8bb09b9b01c410427979",
     "grade": false,
     "grade_id": "cell-bd766c809f5319b0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "3ce18ed2"
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "plot_latent(autoencoder, test_loader)\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "cc4782bce0b7483793f2d27c29f9183a",
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "41dc1bd4409181d2e332053611052eba",
     "grade": false,
     "grade_id": "cell-f49a12f52700d41c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Wir können uns auch die Rekonstruktionen der Eingabedaten an verschiedenen Stellen im Latent Space ansehen. Auch hier sind die Bereiche der einzelnen Ziffern klar erkennbar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "61732a3dbc944c90b6349c7d81ec09ae",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_context_id": "61b9eaf0-4918-4ca4-9ccd-5ce703e58178",
    "execution_millis": 3,
    "execution_start": 1733688846669,
    "source_hash": "4f1ceb7b"
   },
   "outputs": [],
   "source": [
    "def plot_reconstructed(autoencoder, latent_range_x=(-3, 3), latent_range_y=(-3, 3), grid_size=12):\n",
    "\n",
    "    image_size = 28  # Size of each reconstructed image (28x28 for MNIST)\n",
    "    grid_image = np.zeros((grid_size * image_size, grid_size * image_size))  # Grid to hold images\n",
    "\n",
    "    for row_index, latent_y in enumerate(np.linspace(*latent_range_y, grid_size)):\n",
    "        for col_index, latent_x in enumerate(np.linspace(*latent_range_x, grid_size)):\n",
    "            latent_vector = torch.Tensor([[latent_x, latent_y]])  # Latent vector\n",
    "            reconstructed_image = autoencoder.decoder(latent_vector)  # Decode the latent vector\n",
    "            reconstructed_image = reconstructed_image.reshape(image_size, image_size).detach().numpy()\n",
    "            grid_y_start = (grid_size - 1 - row_index) * image_size\n",
    "            grid_y_end = grid_y_start + image_size\n",
    "            grid_x_start = col_index * image_size\n",
    "            grid_x_end = grid_x_start + image_size\n",
    "            grid_image[grid_y_start:grid_y_end, grid_x_start:grid_x_end] = reconstructed_image\n",
    "\n",
    "    # Plot the grid of reconstructed images\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(1-grid_image, cmap='gray', extent=[*latent_range_x, *latent_range_y], interpolation='nearest')\n",
    "    plt.xlabel(\"Latent Dimension 1\")\n",
    "    plt.ylabel(\"Latent Dimension 2\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "221ff6710d6b4c709346172e61a6c98d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "deletable": false,
    "editable": false,
    "execution_context_id": "61b9eaf0-4918-4ca4-9ccd-5ce703e58178",
    "execution_millis": 462,
    "execution_start": 1733688848070,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5e5d8d6443f834a24e6298cee8657fce",
     "grade": false,
     "grade_id": "cell-e4fc02f4ae148e7c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "371cc87a"
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "plot_reconstructed(autoencoder)\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1ccfae7014254b8a877f5e92863eff66",
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f73e689920db83d3bc71b0c5a2f6a7f4",
     "grade": false,
     "grade_id": "cell-a0679aa104780dd7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Aufgabe 3.5 (3 Punkte) - Interpolation\n",
    "\n",
    "Bilder können ineinander umgewandelt werden, in dem die Codes linear interpoliert und anschließend rücktransformiert werden. Vervollständigt dafür die `morph()` Funktion im folgenden Feld. Die Argumente der Funktion sind das Anfangs- und das Endbild sowie die Anzahl der Zwischenbilder.\n",
    "\n",
    "Hinweise: \n",
    "- Ihr könnt hier die `autoencoder.encode()` und `autoencoder.decode()` Funktionen verwenden (siehe Implementierung des Autoencoders), um die Latenten Repräsentationen zu erhalten und zurück zu transformieren.\n",
    "- Ihr könnt `torch.stack` verwenden, um einen Batch für den Encoder zu erstellen\n",
    "- Ein `torch.Tensor` kann durch `.detach().numpy()`in einen Numpy-Array umgewandelt werden.\n",
    "- Ihr könnt mit `torch.unsqueeze(image, 0)` und `torch.squeeze()` eine Batch-Dimension zu einem einzelen Bild hinzufügen bzw. davon entfernen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "0a8368c2f255478aa9e54753915508b0",
    "deepnote_cell_type": "code",
    "deletable": false,
    "execution_context_id": "f7e6c099-c4a7-4fca-93f2-9fa8740aa7b7",
    "execution_millis": 0,
    "execution_start": 1733706514698,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "785c17c89d34b0434653e779cdf87acf",
     "grade": false,
     "grade_id": "morph",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "source_hash": "a701754"
   },
   "outputs": [],
   "source": [
    "def morph(autoencoder, image_1, image_2, num_intermediate_images):\n",
    "    \"\"\"\n",
    "    Performs morphing between two images in the latent space of the autoencoder.\n",
    "    \n",
    "    Args:\n",
    "        image_1 (torch.Tensor): Input tensor of the first image, shape (28, 28).\n",
    "        image_2 (torch.Tensor): Input tensor of the second image, shape (28, 28).\n",
    "        num_intermediate_images (int): Number of intermediate images to generate.\n",
    "    \n",
    "    Returns:\n",
    "        output_imgs (list of numpy.ndarray): List of reconstructed images including intermediates.\n",
    "            - The first image is the reconstruction of `image_1`.\n",
    "            - The last image is the reconstruction of `image_2`.\n",
    "            - The intermediate images are decoded from interpolated latent codes.\n",
    "        code1 (torch.Tensor): Latent code of `image_1`, shape (latent_dims).\n",
    "        code2 (torch.Tensor): Latent code of `image_2`, shape (latent_dims).\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    return output_imgs, code1, code2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c3dda9827a29465fafb359cddfdcfa1d",
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "70ade4133fa45a5d052b0b32cf367cd4",
     "grade": false,
     "grade_id": "cell-158ec1945afa1ca5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Reise durch den Latent Space:**\n",
    "\n",
    "Mit der implementierten `morph`-funktion könnt ihr jetzt eine Reise durch den Latent Space unternehmen. Wählt dazu zwei Bilder aus dem Testdatensatz und lasst euch die interpolierten Bilder anzeigen. Wir können so sehen, wie sich die Rekonstruktionen der Bilder verändern, wenn wir uns durch den Latent Space bewegen und die einzelnen Ziffern ineinander übergehen. Wir plotten hier auch nocheinmal den Latent Space und zeigen die Koordinaten der kodierten Bilder und die Route über die wir uns durch den Latent Space bewegen. So könnt ihr hier nochmal sehen, wie wir uns durch die verschiedenen Bereiche der einzelenen Ziffern bewegen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select two images from the test set\n",
    "# Modify the indices to experiment with different images\n",
    "image_1_idx, image_2_idx = 0, 3\n",
    "image_1, image_2 = test_dataset[image_1_idx][0], test_dataset[image_2_idx][0]\n",
    "\n",
    "# Visualize the original images\n",
    "print(\"Original images:\")\n",
    "visualize_data([image_1, image_2])\n",
    "\n",
    "# Generate the morphed sequence of images\n",
    "num_morphed_images = 10  # Number of intermediate images\n",
    "print(\"Morphed sequence:\")\n",
    "morphed_images, code1, code2 = morph(autoencoder, image_1, image_2, num_morphed_images)\n",
    "visualize_data(morphed_images)\n",
    "\n",
    "# Visualize the latent space and morphed path\n",
    "plot_latent(autoencoder, test_loader)  # Plot the latent space\n",
    "\n",
    "# Add a line between the two latent codes to visualize the interpolation path\n",
    "plt.plot(\n",
    "    [code1[0], code2[0]], \n",
    "    [code1[1], code2[1]], \n",
    "    color='black', linestyle='--', label='Interpolation Path'\n",
    ")\n",
    "\n",
    "# Highlight the latent codes of the original images\n",
    "plt.scatter(\n",
    "    [code1[0]], [code1[1]], \n",
    "    color='red', s=100, label='Code 1 (Image 1)'\n",
    ")\n",
    "plt.scatter(\n",
    "    [code2[0]], [code2[1]], \n",
    "    color='blue', s=100, label='Code 2 (Image 2)'\n",
    ")\n",
    "\n",
    "# Add legend and show the plot\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "48468dfa8e8e436d9e1459a4a73a25c7",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Jetzt folgen noch ein paar Tests, um zu überprüfen, ob der Code funktioniert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "d5b8617537114999875c42496c3cd445",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "deletable": false,
    "editable": false,
    "execution_context_id": "61b9eaf0-4918-4ca4-9ccd-5ce703e58178",
    "execution_millis": 207,
    "execution_start": 1733688882027,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f5a44a37edbc5a54711545852e4f389d",
     "grade": true,
     "grade_id": "image-morphing-reconstruction",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "5c9aa5c9"
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "# ID: image-morphing-reconstruction - possible points: 3\n",
    "\n",
    "t1, t2, n_steps = torch.randint(high=10,size=[28,28])/2, torch.randint(high=10,size=[28,28])/2, 6\n",
    "\n",
    "class TestAutoencoder:\n",
    "    \"\"\"\n",
    "    A mock autoencoder class for testing purposes. Passes data through identity transformations.\n",
    "    Args:\n",
    "        autoencoder (tuple): A tuple of two torch.nn.Module objects (encoder and decoder).\n",
    "    \"\"\"\n",
    "    def __init__(self, autoencoder):\n",
    "        self.encoder = autoencoder[0]  # Encoder module\n",
    "        self.decoder = autoencoder[1]  # Decoder module\n",
    "\n",
    "    def encode(self, x):\n",
    "        \"\"\"Encodes input data.\"\"\"\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def decode(self, z):\n",
    "        \"\"\"Decodes latent space representation.\"\"\"\n",
    "        return self.decoder(z)\n",
    "\n",
    "# Instantiate the mock autoencoder for testing\n",
    "test_autoencoder = TestAutoencoder((torch.nn.Identity(), torch.nn.Identity()))\n",
    "\n",
    "# Call the morph function\n",
    "student_interpolation = morph(test_autoencoder, t1, t2, n_steps)\n",
    "\n",
    "assert len(student_interpolation[0]) == (n_steps + 2), (\n",
    "    f\"Expected {n_steps + 2} images in the morphed sequence, but got {len(student_interpolation[0])}.\"\n",
    ")\n",
    "\n",
    "for i in range(n_steps + 2):\n",
    "    expected_img = (5 * ((i * t2 + (n_steps + 1 - i) * t1) / (n_steps + 1)).detach().numpy()).round(4)\n",
    "    actual_img = (5 * student_interpolation[0][i]).round(4)\n",
    "    assert np.array_equal(actual_img, expected_img), (\n",
    "        f\"Mismatch at step {i}. \"\n",
    "        f\"Expected:\\n{expected_img}\\n\\nGot:\\n{actual_img}\"\n",
    "    )\n",
    "\n",
    "assert student_interpolation[1].shape == (28, 28), (\n",
    "    f\"Expected shape of the first code to be (28, 28), but got {student_interpolation[1].shape}.\"\n",
    ")\n",
    "assert student_interpolation[2].shape == (28, 28), (\n",
    "    f\"Expected shape of the second code to be (28, 28), but got {student_interpolation[2].shape}.\"\n",
    ")\n",
    "assert student_interpolation[0][0].shape == (28, 28), (\n",
    "    f\"Expected shape of the first image in the sequence to be (28, 28), but got {student_interpolation[0][0].shape}.\"\n",
    ")\n",
    "\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4cf5d31c58504cae937940f0cbe77865",
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d40bde4d082fbccd6949ab7d94071ff4",
     "grade": false,
     "grade_id": "cell-bdafdd6205f3fbc1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Dies ist das Ende der Programmieraufgabe. **Vergesst nicht, auch die Fragen auf dem Übungsblatt zu beantworten** ;)"
   ]
  }
 ],
 "metadata": {
  "deepnote_notebook_id": "5314896bf1d64246aedb8319837fadca",
  "deepnote_persisted_session": {
   "createdAt": "2024-12-09T01:30:21.809Z"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
