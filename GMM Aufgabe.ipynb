{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 4 - Gaussian Mixture Models\n",
    "\n",
    "In dieser Aufgabe wollen wir Flächen auf einem Satellitenbild nach Verwendung (land use) klassifizieren. Wir werden versuchen, Pixel mit ähnlichen Farben zu einer Klasse zu gruppieren und so unterschiedliche Landflächen unterscheiden können (Wald, Wüste, Stadt, etc.)\n",
    "\n",
    "Zuerst laden wir das Bild:\n",
    "\n",
    "Für diese Aufgabe benötigen wir die `pillow` Bibliothek. Falls die nächste Zelle bei ihnen einen Fehler produziert, installieren Sie diese mit `conda install pillow` oder `pip install pillow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = Image.open(\"data.png\")\n",
    "data = np.array(image)[:, :, :3].astype(float) / 255\n",
    "print(data.shape)\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Bild ist 500x500 pixel groß und hat drei Farbkanäle. Diese werden unsere features sein.\n",
    "\n",
    "## Gaussian Mixture Models (GMM)\n",
    "\n",
    "Ein GMM besteht aus $K$ Tupeln $(\\alpha_k, \\mu_k, \\Sigma_k), i\\in[k..K]$ für ein vorher festgelegtes $K$. Das GMM beschreibt eine Wahrscheinlichkeitsverteilung:\n",
    "\n",
    "$$P(x)=\\sum_{k=1}^K \\alpha_k\\mathcal{N}(\\mu_k, \\Sigma_k)(x)$$\n",
    "\n",
    "Hier ist $\\mathcal{N}$ die multivariate Gaußverteilung:\n",
    "\n",
    "$$\\mathcal{N}(\\mu, \\Sigma)(x)=\\frac{1}{\\sqrt{(2\\pi)^d|\\Sigma|}}\\exp(-\\frac{1}{2}(x-\\mu)^\\top\\Sigma^{-1}(x-\\mu))$$\n",
    "\n",
    "$|\\Sigma|$ ist die Determinante und $\\Sigma^-1$ die Inverse von $\\Sigma$.\n",
    "\n",
    "Die $\\alpha_k$ sind Verteilungsgewichte, (die a-priori Wahrscheinlichkeiten aus Bayes) und es gilt $\\sum_{k=1}^K\\alpha_k=1$.\n",
    "\n",
    "Wir wollen GMMs zur Klassifikation benutzen, indem wir annehmen, dass jedes $k$ eine Klasse $\\omega_k$ darstellt. Wir können jetzt für einen Datenpunkt $x_i$ ein Klassengewicht bestimmen:\n",
    "\n",
    "$$w_{ik}=p(\\omega_k|x_i)=\\frac{P(x_i|\\omega_k)p(\\omega_k)}{P(x_i)}=\\frac{P(x_i|\\omega_k)p(\\omega_k)}{\\sum_{m=1}^K P(x_i|\\omega_m)\\alpha_m}=\\frac{\\mathcal{N}(\\mu_k, \\Sigma_k)(x_i)\\alpha_k}{\\sum_{m=1}^K \\mathcal{N}(\\mu_m, \\Sigma_m)(x_i)\\alpha_m}$$\n",
    "\n",
    "Bei der Klassifikation wählen wir für $x_i$ die Klasse $\\omega_k$ mit dem höchsten $w_{ik}$. Aber wir benötigen diese Gewichte auch beim Training der Parameter.\n",
    "\n",
    "### Der EM-Algorithmus\n",
    "\n",
    "Wir trainieren die Parameter mit dem Expectation-Maximization (EM) Algorithmus. Er besteht aus zwei Schritten, die abwechselnd wiederholt werden:\n",
    "\n",
    "#### E-Schritt\n",
    "\n",
    "Mit den aktuellen Parametern, berechne $w_{ik}$ für alle $x_i$ und alle $\\omega_k$. Aufgrund der Definition der $w_{ik}$ gilt $\\sum_{k=1}^K w_{ik}=1$. Das Ergebnis ist eine $N\\times K$ Matrix in der sich jede Zeile zu 1 summiert. ($N$ sei die Anzahl der Datenpunkte).\n",
    "\n",
    "#### M-Schritt\n",
    "\n",
    "Benutze die Gewichte und die Daten um neue, bessere Schätzungen der Parameter zu bestimmen. Sei $N_k=\\sum_{i=1}^N w_{ik}$. Die neuen Parameterwerte sind:\n",
    "\n",
    "$$\\alpha_k^{\\text{neu}}=\\frac{N_k}{N}$$\n",
    "\n",
    "$$\\mu_k^{\\text{neu}}=\\frac{1}{N_k}\\sum_{i=1}^N w_{ik}\\cdot x_i$$\n",
    "\n",
    "$$\\Sigma_k^{\\text{neu}}=\\frac{1}{N_k}\\sum_{i=1}^N w_{ik}\\cdot(x_i-\\mu_k^{\\text{neu}})(x_i-\\mu_k^{\\text{neu}})^\\top$$\n",
    "\n",
    "#### Initialisierung und Ende\n",
    "\n",
    "Wir initialisieren die Parameter mit\n",
    "\n",
    "$$\\alpha_k=\\frac{1}{K}$$\n",
    "\n",
    "$$\\mu_k=x_j\\quad \\text{j zufällig aus 1..N}$$\n",
    "\n",
    "$$\\Sigma_k=\\frac{1}{N}\\sum_{i=1}^N (x_i-\\hat{\\mu})(x_i-\\hat{\\mu})^\\top$$\n",
    "\n",
    "Hier ist $\\hat{\\mu}=\\frac{1}{N}\\sum_{i=1}^N x_i$. Das bedeutet, dass $\\Sigma_k$ und $\\alpha_k$ gleich für alle $k$ ist, aber $\\mu_k$ nicht.\n",
    "\n",
    "Um zu entscheiden, wann der Algorithmus beendet ist, berechnen wir nach jedem M-Schritt die log-likelihood:\n",
    "\n",
    "$$\\log l(X)=\\sum_{i=1}^N \\log P(x_i) = \\sum_{i=1}^N \\log \\sum_{k=1}^K \\alpha_k P(x_i|\\omega_k)$$\n",
    "\n",
    "Wenn die log-likelihood um weniger als 1% steigt, beenden wir den Algorithmus.\n",
    "\n",
    "### Aufgabe a) EM-Algorithmus (30 Punkte)\n",
    "\n",
    "Implementieren Sie den E-Schritt, den M-Schritt und die Berechnung der log-likelihood. Verändern Sie die vorgegebenen Methoden nicht, aber sie dürfen zusätzliche Hilfsmethoden schreiben.\n",
    "\n",
    "Hinweise: Verwedenden Sie `np.linalg.inv` und `np.linalg.det` jeweils für das Inverse und die Determinante einer Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMM:\n",
    "    def __init__(self, num_classes, num_dims):\n",
    "        self.num_classes = num_classes\n",
    "        self.num_dims = num_dims\n",
    "        self.priors = np.empty(num_classes)\n",
    "        self.means = np.empty((num_classes, num_dims))\n",
    "        self.covariances = np.empty((num_classes, num_dims, num_dims))\n",
    "    \n",
    "    def fit(self, data):\n",
    "        original_shape = data.shape\n",
    "        assert data.shape[-1] == self.num_dims\n",
    "        data = data.reshape(-1, self.num_dims)\n",
    "        \n",
    "        self.initialize_parameters(data)\n",
    "        \n",
    "        log_likelihood = self.log_likelihood(data) / len(data)\n",
    "        \n",
    "        while True:\n",
    "            weights = self.e_step(data)\n",
    "            assert weights.shape == (len(data), self.num_classes)\n",
    "            assignments = np.argmax(weights, axis=1).reshape(original_shape[:-1])\n",
    "            yield log_likelihood, assignments\n",
    "            assert weights.shape == (len(data), self.num_classes)\n",
    "            self.m_step(data, weights)\n",
    "            new_likelihood = self.log_likelihood(data) / len(data)\n",
    "            if new_likelihood < log_likelihood + 1e-3:\n",
    "                break\n",
    "            log_likelihood = new_likelihood\n",
    "        yield new_likelihood, self.classify(data.reshape(original_shape))\n",
    "    \n",
    "    def classify(self, data):\n",
    "        assert data.shape[-1] == self.num_dims\n",
    "        flat_data = data.reshape(-1, self.num_dims)\n",
    "        \n",
    "        weights = self.e_step(flat_data)\n",
    "        assignments = np.argmax(weights, axis=1)\n",
    "        assignments = assignments.reshape(data.shape[:-1])\n",
    "        return assignments\n",
    "    \n",
    "    def initialize_parameters(self, data):\n",
    "        self.priors[:] = 1 / self.num_classes\n",
    "        self.means[:] = data[np.random.randint(len(data), size=self.num_classes)]\n",
    "        global_mean = data.mean(axis=0)\n",
    "        diff = data - global_mean\n",
    "        global_covariance = np.einsum(\"Ni,Nj->Nij\", diff, diff).mean(axis=0)\n",
    "        self.covariances[:] = global_covariance\n",
    "    \n",
    "    def log_likelihood(self, data):\n",
    "        # Your code here\n",
    "        pass\n",
    "    \n",
    "    def e_step(self, data):\n",
    "        # Your code here\n",
    "        pass\n",
    "    \n",
    "    def m_step(self, data, weights):\n",
    "        # Your code here\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt wenden wir den Algorithmus an. Sie können auch eine andere Anzahl Klassen wählen und den Effekt auf das Ergebnis beobachten.\n",
    "\n",
    "Falls Ihre Implementierung Schwierigkeiten hat, die gesamten Daten zu verarbeiten, können Sie auch mit einem subset der Daten (jeder zweite, dritte, etc.) trainieren.\n",
    "Für die volle Punktzahl sollte Ihre Implementierung mit mindestens 50x50 Datenpunkten in unter 2 Minuten trainieren können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GMM(num_classes=5, num_dims=3)\n",
    "train_data = data\n",
    "# train_data = data[::2,::2]\n",
    "# train_data = data[::5,::5]\n",
    "# train_data = data[::10,::10]\n",
    "\n",
    "print(f\"Training mit {train_data.size // 3} Datenpunkten\")\n",
    "for i, (likelihood, assignment) in enumerate(gmm.fit(data)):\n",
    "    print(f\"Iteration {i} | log-likelihood {likelihood:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe b) Visualisiserung (10 Punkte)\n",
    "\n",
    "Entwickeln Sie mindestens zwei unterschiedliche sinnvolle Visualisierungen für das Ergebnis Ihres Klassifikators.\n",
    "\n",
    "Vorschläge:\n",
    "\n",
    "* Mit `PIL.Image.fromarray` können Sie ein numpy array (Datentyp `np.uint8`, normalisiert auf `[0,255]`) in ein Bild umwandeln. Wenn die Ausgabe einer Zelle (also der Wert auf der letzten Zeile) das Bild ist, wird es im Notebook dargestellt\n",
    "* Mit `matplotlib.pyplot.imshow` können Sie sowohl Bilder als auch heatmaps darstellen\n",
    "* Mit `IPython.display.Markdown` können Sie in Python erzeugten Markdown code im Notebook darstellen lassen und damit z.B. eine Tabelle erzeugen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dies sind nur Vorschläge für Größen, die Sie darstellen könnten:\n",
    "assignments = gmm.classify(data)\n",
    "means = gmm.means\n",
    "covariances = gmm.covariances\n",
    "class_counts = np.bincount(assignments.reshape(-1))\n",
    "\n",
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
