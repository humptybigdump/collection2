{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "6EcRmLpp65nz",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exercise 1, Mini Image Classifier (Colab Version), 28P(oints)\n",
    "\n",
    "## Lab Instructions\n",
    "All your answers of this exercise should be written **in this notebook**.\n",
    "You shouldn't need to write or modify any other files.\n",
    "\n",
    "**You should execute every block of code to not miss any dependency. For the\n",
    "training tasks, your notebook should contain the classification accuracy (the\n",
    " figures are NOT necessary however).\n",
    " Please DO NOT clear the notebook output when you submit it.\n",
    " Please DO NOT upload the dataset when you submit your homework.**\n",
    "\n",
    "This exercise was developed by Ge Li for the KIT Cognitive Systems Lecture,\n",
    "July 2021.\n",
    "\n",
    "## Task instructions:\n",
    "In this jupyter notebook, you are going to define multiple **Image\n",
    "classifiers** with different structures. Read the instruction and example code\n",
    "carefully and finish the tasks. You can run the training procedure and\n",
    "thereby verify your computation and implementation.<br>\n",
    "\n",
    "Detailed instructions:\n",
    "\n",
    "0. You need to connect colab to your google drive in order to download the CIFAR-10 data set. Colab provides a GPU by clicking \"Runtime\" -> \"Change runtime type\" and then selecting GPU as a hardware accelerator.<br><br>\n",
    "\n",
    "1. The dataset you are working with is CIFAR-10. The code in the cell of the **data_loader** will download and manage this dataset for you. You do not\n",
    " need to write any code for it.<br><br>\n",
    "\n",
    "2. The deep learning platform you are working with is PyTorch. In the scope of\n",
    "this homework, you can learn the fundamental knowledge from the instructions.\n",
    " You don't have to spend much time on external materials / tutorials.<br><br>\n",
    "\n",
    "3. In this notebook, you will focus on the Neural Network models for image\n",
    "classification. A classifier with fully connected layers is given as an\n",
    "example. This example mainly contains two parts: a **constructor** in which\n",
    "all the layers to be used are initialized (except activation function), and a\n",
    "**forward** function, where the forward pass process of the network is defined. In PyTorch, once the forward function of a network is given, the gradient of the loss function with respect to the network parameters can be automatically computed and back-propagated.<br><br>\n",
    "\n",
    "4. In your model's constructor, you may need to call these functions:\n",
    "    - Define fully connected layers: **nn.Linear(in_features, out_features)**,\n",
    "such as: nn.Linear(64, 10)\n",
    "    - Define 2-D convolutional layers: **nn.Conv2d(in_channels, out_channels,\n",
    "kernel_size, stride, padding)**, such as: nn.Conv2d(8, 16, 5, padding=0)\n",
    "    - Define max-pooling layers: **nn.MaxPool2d(kernel_size, stride)**, such as:\n",
    "nn.MaxPool2d(2, 2)<br><br>\n",
    "\n",
    "5. In your model's forward function, you may need to call these functions:\n",
    "    - Flatten the 3rd order tensor to 1st order tensor: e.g. **x = torch\n",
    "    .flatten(x, 1)**\n",
    "    - Relu activation function: e.g. **x = F.relu(x)**<br><br>\n",
    "\n",
    "6. All the training and plotting related code are offered by the **fit** function. The contents can be described in the pseudo code below, which is also a common workflow in deep learning. <br>\n",
    "    - Get train, valid and test data-loader to load data from dataset.\n",
    "    - Initialize the loss function and optimizer for parameters' updating.\n",
    "    - Loop in epochs:\n",
    "        - Loop in batch of training dataset:\n",
    "            - Compute the output using forward function\n",
    "            - Compute the loss using output and labels\n",
    "            - Applying back-propagation and update network parameters\n",
    "            - Record the training loss\n",
    "        - Loop in batch of validation dataset:\n",
    "            - Compute the output using forward function\n",
    "            - Compute the loss using output and labels\n",
    "            - Record the validation loss\n",
    "        - Plotting the training and validation loss for each epoch.\n",
    "        - save model's parameters if the model achieves a better performance\n",
    "        - break the loop (early stopping) if the validation loss keeps\n",
    "        increasing.\n",
    "    - Apply the model with the best parameters to the test dataset and get the\n",
    "    result (classification accuracy).\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mya2elwh7UTP",
    "outputId": "72c6f1ee-f5b0-4efc-e192-b53781a8866b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# Your work will be stored in a folder called `cogsys_ss22_hw6` by default to prevent Colab\n",
    "# instance timeouts from deleting your edits.\n",
    "# We do this by mounting your google drive on the virtual machine created in this colab\n",
    "# session. For this, you will likely need to sign in to your Google account and copy a\n",
    "# passcode into a field below\n",
    "\n",
    "import os\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uo2IGeMw7ch3",
    "outputId": "771a00e0-ac59-492f-eae9-bf49e9a26149"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/My Drive/cogsys_ss22_hw6\n"
     ]
    }
   ],
   "source": [
    "# Create paths in your google drive\n",
    "\n",
    "DRIVE_PATH = '/content/gdrive/My\\ Drive/cogsys_ss22_hw6'\n",
    "DRIVE_PYTHON_PATH = DRIVE_PATH.replace('\\\\', '')\n",
    "if not os.path.exists(DRIVE_PYTHON_PATH):\n",
    "  %mkdir $DRIVE_PATH\n",
    "\n",
    "# the space in `My Drive` causes some issues,\n",
    "# make a symlink to avoid this\n",
    "SYM_PATH = '/content/cogsys_ss21'\n",
    "if not os.path.exists(SYM_PATH):\n",
    "  !ln -s $DRIVE_PATH $SYM_PATH\n",
    "%cd $SYM_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x5F3KuZiU4K8"
   },
   "source": [
    "Run the next cell once to download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xBf4PFCZ8NSn",
    "outputId": "4d2a8019-b8df-43dd-9bb6-8313d5343448"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# DO NOT MODIFY THIS BLOCK\n",
    "# DO NOT MODIFY THIS BLOCK\n",
    "# DO NOT MODIFY THIS BLOCK\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Fix random seed to make sure the result in your computer is reproducible\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "def get_data_loader():\n",
    "    # Define a composed transform of pre-processing the dataset\n",
    "    transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                                                         (0.5, 0.5, 0.5))])\n",
    "\n",
    "    # Load CIFAR-10 dataset\n",
    "    train_set = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                             download=True, transform=transform)\n",
    "    train_set, valid_set = torch.utils.data.random_split(train_set, [40000,\n",
    "                                                                     10000])\n",
    "\n",
    "    test_set = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                            download=True, transform=transform)\n",
    "\n",
    "    # Construct data loaders\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=512,\n",
    "                                               shuffle=True, num_workers=2)\n",
    "    valid_loader = torch.utils.data.DataLoader(test_set, batch_size=1024,\n",
    "                                               shuffle=False, num_workers=2)\n",
    "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=512,\n",
    "                                              shuffle=False, num_workers=2)\n",
    "\n",
    "    return train_loader, valid_loader, test_loader\n",
    "\n",
    "# Get data loaders\n",
    "# data loader is an object used as as an iterator, which can be use in the\n",
    "# for... in loop, such as:\n",
    "#\n",
    "#             for data in dataloader:\n",
    "#                 blablabla...\n",
    "\n",
    "train_loader, valid_loader, test_loader = get_data_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PsBEN6n9S0K2"
   },
   "outputs": [],
   "source": [
    "# DO NOT MODIFY THIS BLOCK\n",
    "# DO NOT MODIFY THIS BLOCK\n",
    "# DO NOT MODIFY THIS BLOCK\n",
    "\n",
    "\n",
    "# Import Python libs\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import trange\n",
    "\n",
    "\n",
    "def fit(model, max_epochs, device, early_stop=True):\n",
    "    \"\"\"\n",
    "    Train model, store the best model, and run a final test.\n",
    "    :param model: NN model used in the image classification\n",
    "    :param max_epochs: the iteration number for using all data in train_dataset\n",
    "    :param early_stop: stop the training if the loss in valid_dataset\n",
    "    keeps increases\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    # Use cross entropy as the loss function in classification\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Define an optimizer for gradient descent\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Initialize a dict to store the best model during training\n",
    "    best_model_dict = model.state_dict()\n",
    "\n",
    "    # Define a iterator object to print progress bar\n",
    "    epochs = trange(max_epochs, desc=model.__class__.__name__ + ' Training',\n",
    "                    unit='Epoch', dynamic_ncols=True)\n",
    "\n",
    "    # Record the training and validation loss\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "\n",
    "    # Initialize a figure to show loss functions\n",
    "    plt.figure()\n",
    "\n",
    "    # Main loop. Each iteration will use all the data in training dataset,\n",
    "    # called as epoch.\n",
    "    for epoch in epochs:\n",
    "        # Unfreeze the parameters in the NN model\n",
    "        model.train()\n",
    "        train_batch_num = 0\n",
    "        train_loss = 0.0\n",
    "        # each batch, a group of data in the dataset form a batch.\n",
    "        for inputs, labels in train_loader:\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            # zero the parameter gradients. Every time after do gradient\n",
    "            # back-propagation, the gradient will remain in the model,\n",
    "            # we need to clean it before update again.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # compute outputs, here your \"forward\" function in the model will\n",
    "            # be called by PyTorch automatically.\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Compute loss, here the loss is averaged to the batch.\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # loss back propagation\n",
    "            loss.backward()\n",
    "\n",
    "            # The parameters in the model get updated\n",
    "            optimizer.step()\n",
    "\n",
    "            # get some statistics\n",
    "            train_loss += loss.item()\n",
    "            train_batch_num += 1\n",
    "\n",
    "        # save train loss of current epoch\n",
    "        train_loss_list.append(train_loss / train_batch_num)\n",
    "\n",
    "        # Before we evaluate the data, we need to frozen the parameters in\n",
    "        # the model\n",
    "        model.eval()\n",
    "\n",
    "        # Use validation dataset to evaluate the training result. This can avoid\n",
    "        # over-fitting\n",
    "        valid_loss = 0.0\n",
    "        valid_batch_num = 0\n",
    "\n",
    "        for inputs, labels in valid_loader:\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Compute loss\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # get statistics\n",
    "            valid_loss += loss.item()\n",
    "            valid_batch_num += 1\n",
    "\n",
    "        # save validation loss of current epoch\n",
    "        valid_loss_list.append(valid_loss / valid_batch_num)\n",
    "\n",
    "        # export the training losses to the progress bar\n",
    "        epochs.set_postfix(OrderedDict({\"train_loss\": train_loss_list[-1],\n",
    "                                        \"valid_loss\": valid_loss_list[-1]}))\n",
    "\n",
    "        # Record the best model\n",
    "        if epoch > 0 and valid_loss_list[-1] == min(valid_loss_list):\n",
    "            best_model_dict = model.state_dict()\n",
    "\n",
    "        # Apply early stopping\n",
    "        if early_stop and epoch > 5 and min(valid_loss_list) not in \\\n",
    "                valid_loss_list[-5:]:\n",
    "            break\n",
    "\n",
    "    # Plot result in a figure\n",
    "    plt.plot(range(1, epoch + 2), train_loss_list, color='b')\n",
    "    plt.plot(range(1, epoch + 2), valid_loss_list, color='r')\n",
    "    plt.legend([\"Train loss\", \"valid loss\"])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Cross-Entropy Loss\")\n",
    "    plt.title(\"Training and validation loss in \" + model.__class__.__name__)\n",
    "    plt.show()\n",
    "    print(\"Finished Training.\")\n",
    "\n",
    "    # Training is finished, now get our best model to test\n",
    "    model.load_state_dict(best_model_dict)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        # We use test dataset for testing\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('Accuracy of the network on the 10000 test images: %.2f %%' % (\n",
    "            100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EPAPa51p65n2",
    "outputId": "a4697d1b-419f-42b3-e624-0061484bd991",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# DO NOT MODIFY THIS BLOCK\n",
    "# DO NOT MODIFY THIS BLOCK\n",
    "# DO NOT MODIFY THIS BLOCK\n",
    "\n",
    "# Import Python libs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Fix random seed to make sure the result in your computer is reproducible\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Max training epochs\n",
    "max_epochs = 100\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0uewtdMU65n4",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Task a)\n",
    "- Read the implementation of fully connected layers classifier, then run the\n",
    "cell afterwards to train this classifier. The training result will be shown\n",
    "automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AWakAjEH65n4",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT MODIFY THIS BLOCK\n",
    "# DO NOT MODIFY THIS BLOCK\n",
    "# DO NOT MODIFY THIS BLOCK\n",
    "\n",
    "class FCLayersNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Image classifier using fully connected layers\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Model Constructor, Initialize all the layers to be used\n",
    "        \"\"\"\n",
    "        super(FCLayersNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(32 * 32 * 3, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 256)\n",
    "        self.fc3 = nn.Linear(256, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        This function defines the forward pass of this net model.\n",
    "        Once this function is defined, the gradient back-propagation can be\n",
    "        automatically computed by PyTorch.\n",
    "\n",
    "        :param x: input data of this model\n",
    "        :return: output data of this model\n",
    "        \"\"\"\n",
    "        # The original data is 3rd order tensor, we need to flatten it to 1st\n",
    "        # order tensor, as the input of the fully connected layer.\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        # The data pass through the fully connected layers one after another\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc4(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7IPeWvfy65n6",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- Run next cell and see the training progress and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7nqKSE9y65n6",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Run me\n",
    "%matplotlib inline\n",
    "fc_net = FCLayersNet().to(device)\n",
    "fit(fc_net, max_epochs, device, early_stop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIC-s1c-65n7",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Task b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLNwEOTt65n8",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- Write down the missing cells:<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PpX8iiOV65n8"
   },
   "source": [
    "    - I: , II: , III: , IV: , V: , VI: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7TG2O5P65n9"
   },
   "source": [
    "- Finish the implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8vXO2B2_65n9",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: PLEASE FINISH THE IMPLEMENTATION IN THIS BLOCK\n",
    "# TODO: PLEASE FINISH THE IMPLEMENTATION IN THIS BLOCK\n",
    "# TODO: PLEASE FINISH THE IMPLEMENTATION IN THIS BLOCK\n",
    "\n",
    "class ConvLayersNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Image classifier using convolutional layers\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Model Constructor, Initialize all the layers to be used\n",
    "        \"\"\"\n",
    "        super(ConvLayersNet, self).__init__()\n",
    "        ########   Your code begins here   ########\n",
    "\n",
    "        ########   Your code ends here   ########\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        This function defines the forward pass of this net model.\n",
    "        Once this function is defined, the gradient back-propagation can be\n",
    "        automatically computed by PyTorch.\n",
    "\n",
    "        :param x: input data of this model\n",
    "        :return: output data of this model\n",
    "        \"\"\"\n",
    "        ########   Your code begins here   ########\n",
    "\n",
    "        ########   Your code ends here   ########\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6NggHUI65n-",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- Run next cell and see the training progress and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YnsmLqc465n-",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run me\n",
    "%matplotlib inline\n",
    "conv_net = ConvLayersNet().to(device)\n",
    "fit(conv_net, max_epochs, device, early_stop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RtVcDFQg65n_"
   },
   "source": [
    "### Task c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ExIde9sY65n_"
   },
   "source": [
    "- Recall the knowledge in Cognitive system lecture, what kind of benefits can\n",
    "we expect when applying max-pooling layer in CNNs?<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kp_tIk665oA"
   },
   "source": [
    "- Write down the missing cells:<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66zw1o2s65oA"
   },
   "source": [
    "    - I: , II: , III: , IV: , V: , VI: , VII: , VIII: , IX: , X: , XI: , XII:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OEKdrpXA65oA"
   },
   "source": [
    "- Finish the implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S5BDJoOE65oB",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: PLEASE FINISH THE IMPLEMENTATION IN THIS BLOCK\n",
    "# TODO: PLEASE FINISH THE IMPLEMENTATION IN THIS BLOCK\n",
    "# TODO: PLEASE FINISH THE IMPLEMENTATION IN THIS BLOCK\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Image classifier using CNNs with max pooling channels.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Model Constructor, Initialize all the layers to be used\n",
    "        \"\"\"\n",
    "        super(CNN, self).__init__()\n",
    "        ########   Your code begins here   ########\n",
    "\n",
    "        ########   Your code ends here   ########\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        This function defines the forward pass of this net model.\n",
    "        Once this function is defined, the gradient back-propagation can be\n",
    "        automatically computed by PyTorch.\n",
    "\n",
    "        :param x: input data of this model\n",
    "        :return: output data of this model\n",
    "        \"\"\"\n",
    "        ########   Your code begins here   ########\n",
    "\n",
    "        ########   Your code ends here   ########\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8XzOn8r65oB",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- Run next cell and see the training progress and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3op8aHDR65oB",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run me\n",
    "%matplotlib inline\n",
    "cnn = CNN().to(device)\n",
    "fit(cnn, max_epochs, device, early_stop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHe8b8tO65oC"
   },
   "source": [
    "### Task d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fz3lH3d065oC"
   },
   "source": [
    "- Write down the missing cells:<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Mtt-VMi65oC"
   },
   "source": [
    "    - I: , II: , III: , IV: , V: , VI: , VII: , VIII: , IX: , X: , XI: , XII: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0NOiJvr65oD"
   },
   "source": [
    "- Finish the implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YyMSTwLS65oD",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: PLEASE FINISH THE IMPLEMENTATION IN THIS BLOCK\n",
    "# TODO: PLEASE FINISH THE IMPLEMENTATION IN THIS BLOCK\n",
    "# TODO: PLEASE FINISH THE IMPLEMENTATION IN THIS BLOCK\n",
    "\n",
    "class MiniResNetSimple(nn.Module):\n",
    "    \"\"\"\n",
    "    Image classifier using ResNets with small channel size.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Model Constructor, Initialize all the layers to be used\n",
    "        \"\"\"\n",
    "        super(MiniResNetSimple, self).__init__()\n",
    "        ########   Your code begins here   ########\n",
    "\n",
    "        ########   Your code ends here   ########\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        This function defines the forward pass of this net model.\n",
    "        Once this function is defined, the gradient back-propagation can be\n",
    "        automatically computed by PyTorch.\n",
    "\n",
    "        :param x: input data of this model\n",
    "        :return: output data of this model\n",
    "        \"\"\"\n",
    "        ########   Your code begins here   ########\n",
    " \n",
    "        ########   Your code ends here   ########\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evOlelCG65oD"
   },
   "source": [
    "- Run next cell and see the training progress and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5hlfz2Ls65oD",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run me\n",
    "%matplotlib inline\n",
    "resnet = MiniResNetSimple().to(device)\n",
    "fit(resnet, max_epochs, device, early_stop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-F3gwN9G55z5"
   },
   "source": [
    "## Task e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8OHfNYxz6NzR"
   },
   "source": [
    "- Write down the missing cells:<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Zgoje9U80tq"
   },
   "source": [
    "    - I: , II: , III: , IV: , V: , VI: , VII: , VIII: , IX: , X: , XI: , XII:, XIII: , XIV:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJjwNByf6QRu"
   },
   "source": [
    "- Finish the implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "shMGG-yYmuXH",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: PLEASE FINISH THE IMPLEMENTATION IN THIS BLOCK\n",
    "# TODO: PLEASE FINISH THE IMPLEMENTATION IN THIS BLOCK\n",
    "# TODO: PLEASE FINISH THE IMPLEMENTATION IN THIS BLOCK\n",
    "\n",
    "class MiniResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Image classifier using ResNets with increasing channel size.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Model Constructor, Initialize all the layers to be used\n",
    "        \"\"\"\n",
    "        super(MiniResNet, self).__init__()\n",
    "        ########   Your code begins here   ########\n",
    "\n",
    "        ########   Your code ends here   ########\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        This function defines the forward pass of this net model.\n",
    "        Once this function is defined, the gradient back-propagation can be\n",
    "        automatically computed by PyTorch.\n",
    "\n",
    "        :param x: input data of this model\n",
    "        :return: output data of this model\n",
    "        \"\"\"\n",
    "        ########   Your code begins here   ########\n",
    " \n",
    "        ########   Your code ends here   ########\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aM7sPkOtpTiJ",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run me\n",
    "%matplotlib inline\n",
    "resnet2 = MiniResNet().to(device)\n",
    "fit(resnet2, max_epochs, device, early_stop=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ex1_colab.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
