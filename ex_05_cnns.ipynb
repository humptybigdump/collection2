{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8c9ca7132425b18e5eb165388ff393f7",
     "grade": false,
     "grade_id": "cell-95c8b2f6eb9ab752",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Grundlagen der Künstlichen Intelligenz - Wintersemester 2024/25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4469380a617d67490197434d0b9ed73a",
     "grade": false,
     "grade_id": "cell-b4eda93434fa8d52",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Übung 5: Convolutional Neural Networks\n",
    "\n",
    "---\n",
    "\n",
    "> 'Grundlagen der künstlichen Intelligenz' im Wintersemester 2024/2025\n",
    ">\n",
    "> - T.T.-Prof. Benjamin Schäfer, benjamin.schaefer@kit.edu\n",
    "> - Prof. Gerhard Neumann, gerhard.neumann@kit.edu\n",
    "\n",
    "---\n",
    "\n",
    "In dieser Übung werden wir uns mit Convolutions und CNNs beschäftigen. Wie beim letzten Übungsblatt verwenden wir Pytorch. Zum Auffrischen könnt ihr euch folgendes Einstiegstutorial anschauen: https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html, sowie das Pytorch Tutorial aus der Übung vom 06.12.24. \n",
    "\n",
    "## GPU Training\n",
    "Im Gegensatz zum letzten Übungsblatt funktioniert das Training nur sinnvoll auf einer GPU. Wenn ihr Google Collab benutzt, könnt ihr dies auswählen, indem ihr **oben rechts auf das Dropdown Menü** (\"Additional connection options\") klickt:\n",
    "![GPU Selection](https://i.imgur.com/dWzXhG9.png)\n",
    "Geht dann auf **\"Change Runtime type\"** und wählt die **\"T4 GPU\"** aus:\n",
    "![GPU Selection](https://i.imgur.com/iEUn10Y.png)\n",
    "Die Session muss anschließend neu gestartet werden. Ihr habt kostenlos ein paar GPU Stunden pro Tag zur Verfügung. \n",
    "\n",
    "**Hinweis:** Das Training selbst wird nicht bewertet, nur eure Implementierung der Modelle. Theoretisch kann das Übungsblatt also auch ohne GPU Support gelöst werden. Allerdings könnt ihr dann die Modelle nur extrem langsam/gar nicht trainieren.\n",
    "\n",
    "### Übungsteam\n",
    "\n",
    "- Philipp Dahlinger, philipp.dahlinger@kit.edu\n",
    "- Nicolas Schreiber, nicolas.schreiber@kit.edu\n",
    "- Sebastian Pütz, sebastian.puetz@kit.edu\n",
    "- Ulrich Oberhofer, ulrich.oberhofer@kit.edu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5c3e77930c80392b268cd7a75b7d8f81",
     "grade": false,
     "grade_id": "cell-a31d058c10007ec1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Gruppenabgabe\n",
    "\n",
    "Die Übungsblätter können in Gruppen von bis zu **3 Studierenden** abgegeben werden. **Jede Person aus der Gruppe muss die finale Version der Abgabe über Ilias hochladen**, es genügt nicht, dass nur eine Person aus der Gruppe dies tut. Es ist prinzipiell möglich, im Laufe des Semesters sich einer neuen Gruppe anzuschließen, sollte sich die eigene Gruppe vorzeitig auflösen. Generell muss jede Gruppe ihre eigene Lösung hochladen, wir werden die Abgaben auf Duplikate überprüfen.\n",
    "\n",
    "Die Gruppen werden automatisch erfasst, **gebt deshalb die u-Kürzel eurer Gruppenmitglieder in die folgende Zelle ein.** Falls eure Gruppe nur aus 2 Studierenden besteht, oder ihr alleine abgibt, lasst die verbleibenden Felder frei. Hier ein Beispiel für eine Gruppe bestehend aus uabcd und uefgh:\n",
    "\n",
    "_U-Kürzel der Gruppenmitglieder:_\n",
    "\n",
    "_Mitglied 1: uabcd_\n",
    "\n",
    "_Mitglied 2: uefgh_\n",
    "\n",
    "_Mitglied 3:_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U-Kürzel der Gruppenmitglieder:\n",
    "\n",
    "Mitglied 1:\n",
    "\n",
    "Mitglied 2:\n",
    "\n",
    "Mitglied 3:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b0eebd04c9b5ffc45e166632b26d022f",
     "grade": false,
     "grade_id": "cell-1aeddd52354875b6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Auto-grading\n",
    "\n",
    "Wir nutzen ein auto-grading System, welches eure abgegebenen Jupyter Notebooks automatisch analysiert und über\n",
    "hidden Tests auf Richtigkeit prüft. Über diese Tests werden die Punkte bestimmt, die ihr für das Übungsblatt erhaltet.\n",
    "\n",
    "Damit das auto-grading reibungslos funktioniert bitte folgende Dinge beachten:\n",
    "\n",
    "- Vor dem Abgeben eines Notebooks bitte testen, dass alles von vorne bis hinten ohne Fehler durchläuft.\n",
    "- Zellen, welche mit \"### DO NOT CHANGE ###\" markiert sind dürfen weder gelöscht noch bearbeitet werden\n",
    "- Eure Lösung muss in die richtige Zelle (markiert mit \"# YOUR CODE HERE\") eingetragen werden.\n",
    "    - (dabei natürlich den NotImplementedError löschen!)\n",
    "- Es gibt potentiell scheinbar leere Zellen, die auch mit \"### DO NOT CHANGE ###\" markiert sind. Auch diese dürfen nicht bearbeitet oder gelöscht werden.\n",
    "    - Falls dies doch gemacht wird, dann wird das automatische Grading nicht funktionieren und ihr erhaltet keine Punkte.\n",
    "    - Wir werden hier strikt handeln und keine Ausnahmen machen, falls jemand doch Zellen verändert, die eindeutig als readonly markiert sind!\n",
    "- Die Jupyter Notebooks haben inline Tests (für euch sichtbar), welche euer Ergebnis auf grobe Richtigkeit überprüfen.\n",
    "    - Diese sind primär für euch, um Fehler zu erkennen und zu korrigieren.\n",
    "    - Die inline Tests, die ihr im Notebook sehen könnt, sind allerdings nicht die Tests welche für das Grading verwendet werden!\n",
    "    - Die inline Tests sind eine notwendige Bedingung, um beim Grading der Aufgabe Punkte zu erhalten!\n",
    "\n",
    "# **WICHTIG** Abgabe des Notebooks\n",
    "- Bitte das Jupyter Notebook mit dem ursprünglichen Dateinamen ins Ilias hochladen (\"ex_05_cnns.ipynb\")\n",
    "- Bitte Jupyter Notebook und handgeschriebene PDF einzeln hochladen, nicht als ZIP.\n",
    "- Bitte darauf achten, dass die Jupyter Notebook Zell-Metadaten erhalten bleiben. Das ist eigentlich immer der Fall,\n",
    "in wenigen Fällen gab es hier jedoch Probleme. Um auf Nummer Sicher zu gehen bitte das Notebook vor der Abgabe ein Mal\n",
    "in einem normalen Texteditor öffnen und nach \"nbgrader\" suchen. Wenn hier dann keine entsprechenden JSON-Einträge auftauchen\n",
    "dann sind leider die Metadaten verloren gegangen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2d9db0b09c34f3fa7b5fd9cfff272c35",
     "grade": false,
     "grade_id": "cell-f25aa5f234486268",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 1. Convolutions\n",
    "In dieser Aufgabe wollen wir ein paar klassische Convolution Filter nachimplementieren. \n",
    "Diese wenden wir dann auf mehreren Beispielbildern an, und visualisieren welche Merkmale die Filter jeweils extrahieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6eee44f0f4e4dad586bace07b57d609b",
     "grade": false,
     "grade_id": "cell-7deb4755394338c3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "#imports\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "from PIL import Image, ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import os\n",
    "\n",
    "grading_env_var = os.getenv('NBGRADER_EXECUTION', None)\n",
    "# variable to check if notebook is in grading mode to skip trainings\n",
    "is_grading = (grading_env_var == \"autograde\" or grading_env_var == \"validate\")\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "70eb1c6c9d7fcca445cce59ac229933e",
     "grade": false,
     "grade_id": "cell-41fe6bc609e65d69",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "def vis_filter_pics(left_img, right_img, left_cmap='gray', right_cmap='gray', title=None):\n",
    "    f, axarr = plt.subplots(1, 2, figsize=(14,4))\n",
    "    f.suptitle(title)\n",
    "    axarr[0].imshow(left_img, cmap=left_cmap, interpolation='nearest')    \n",
    "    axarr[1].imshow(right_img, cmap=right_cmap, interpolation='nearest')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7884a896b0b3eb3dbdc888fd310a97b0",
     "grade": false,
     "grade_id": "cell-194670bf42c6f029",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "# Load the example picture\n",
    "if not is_grading:\n",
    "    # URL of the image\n",
    "    url = \"https://drive.google.com/uc?id=1MSs2afO4VEB2EezEF6zokVl4xElod8oY\"\n",
    "\n",
    "    # Download the image\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Save the image to a file\n",
    "        with open(\"edge_detection_gecko.jpeg\", \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "        print(\"Image downloaded and saved as 'edge_detection_gecko.jpeg'\")\n",
    "    else:\n",
    "        print(f\"Failed to download image. Status code: {response.status_code}\")\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "011dfe4030c67f9b8a5fe61a2eeaaea3",
     "grade": false,
     "grade_id": "cell-36a0d4636f823bcf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "test_image = Image.open(\"edge_detection_gecko.jpeg\")\n",
    "\n",
    "# Produce a grayscaled version of that image\n",
    "gray_test_image = ImageOps.grayscale(test_image)\n",
    "\n",
    "# Convert the PIL Images to numpy arrays\n",
    "test_image = np.array(test_image)\n",
    "gray_test_image = np.array(gray_test_image)\n",
    "\n",
    "vis_filter_pics(test_image, gray_test_image, title=\"RGB and Gray Image\")\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0a5d6bc2e5cd26ececabcccf40d567a6",
     "grade": false,
     "grade_id": "cell-c31f00027cb2576e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.1 Implementierung einer Convolution (2 Punkte)\n",
    "Als Grundlage für die späteren Kantenerkennungsaufgaben benötigen wir eine Methode, die es erlaubt, einen 2D-Convolution-Kernel auf ein Single-Channel-Bild anzuwenden.\n",
    "\n",
    "Vervollständige dazu die Funktion convolve2D in der nächsten Zelle. Diese Funktion erhält zwei Eingabeparameter:\n",
    "\n",
    "- `input_array`: ein 2-dimensionales numpy-Array, das ein Single-Channel-Bild repräsentiert.\n",
    "- `kernel`: ein 2-dimensionales numpy-Array, das den Convolution-Kernel darstellt.\n",
    "Die Funktion soll ein neues 2D-numpy-Array zurückgeben, das das Ergebnis der Convolution-Operation enthält.\n",
    "\n",
    "Hinweise:\n",
    "- Der Datentyp des `input_array` wird entweder uint oder int sein. Das Rückgabe-Array soll jedoch immer ein int32-numpy-Array sein.\n",
    "- Verwende **kein Padding** (kein Hinzufügen von extra Zeilen und Spalten). Beachte dabei, dass die Ausgabe aufgrund des fehlenden Paddings eine kleinere Form (Shape) als das Eingabebild haben wird. Dies ist bei der Implementierung der Methode zu berücksichtigen.\n",
    "- Nutze die Formulierung mit Cross Correlation, um die Convolution-Operation zu implementieren. (Vl. 10, Folie 19, unten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9136e54e5343e82069868388ceafce2d",
     "grade": false,
     "grade_id": "cell-1f85d98eeea7c186",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def convolve2d(input_array, kernel):\n",
    "    \"\"\"\n",
    "    Apply 2D convolution to an input array with a given kernel using simple numpy operations.\n",
    "    \n",
    "    Parameters:\n",
    "    input_array (numpy.ndarray): 2D input array to be convolved with shape [input_height, input_width]\n",
    "    kernel (numpy.ndarray): 2D convolution kernel with shape [kernel_height, kernel_width]\n",
    "    \n",
    "    Returns:\n",
    "    np.ndarray: Result of the convolution operation\n",
    "    \"\"\"\n",
    "    # Get dimensions\n",
    "    input_height, input_width = input_array.shape\n",
    "    kernel_height, kernel_width = kernel.shape\n",
    "    \n",
    "    # Calculate the width and height of the output produced by the convolution\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Initialize output array\n",
    "    output = np.zeros((output_height, output_width), dtype=np.int32)\n",
    "    \n",
    "    # Implement the convolution itself\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "489fc434a8983607d204b8535a164196",
     "grade": true,
     "grade_id": "Ex_1_1",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "# ID: Ex_1_1 - possible points: 2\n",
    "\n",
    "# Tests for 1.1:\n",
    "test_kernel = np.array([[0, 0, 0], [0, 1, 0], [0,0,0]])\n",
    "test_sample_image = np.eye(500, dtype=np.uint8)\n",
    "test_convolved_image = convolve2d(test_sample_image, test_kernel)\n",
    "\n",
    "assert test_convolved_image.dtype == np.int32\n",
    "assert np.all(np.equal(test_convolved_image, np.eye(498, dtype=np.int32)))\n",
    "\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c153a4d0a3b4589bb64adcd8c20fa7af",
     "grade": false,
     "grade_id": "cell-120fe534488cb5fc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In der nächsten Zelle haben wir einige Beispielmethoden implementiert, die jeweils einen einfachen Convolution-Kernel verwenden, um Kanten in horizontaler und vertikaler Richtung zu erkennen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def left_right_edge_detection(im: np.array):\n",
    "    kernel = np.array([[-1, 1]], dtype=np.int32)\n",
    "    return convolve2d(im, kernel)\n",
    "\n",
    "def top_down_edge_detection(im: np.array):\n",
    "    kernel = np.array([[-1], [1]], dtype=np.int32)\n",
    "    return convolve2d(im, kernel)\n",
    "\n",
    "\n",
    "# Detect left_right edges and visualize them\n",
    "left_right_edges = left_right_edge_detection(gray_test_image)\n",
    "\n",
    "# Detect top_down edges and visualize them\n",
    "top_down_edges = top_down_edge_detection(gray_test_image)\n",
    "\n",
    "vis_filter_pics(left_right_edges, top_down_edges, title=\"Left_Right and Top_Down Edges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4a4bcac37981ca588b2f13621484e489",
     "grade": false,
     "grade_id": "cell-c4562478e7db5f4d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.2 Laplacian Convolution Kernel (1 Punkt)\n",
    "In der letzten Zelle haben wir zwei einfache Convolution-Kernels implementiert, die jeweils nur horizontale oder vertikale Kanten erkennen können.\n",
    "\n",
    "In dieser Aufgabe sollst du den Laplace-Kernel implementieren, der sowohl horizontale als auch vertikale Kanten erkennen kann. Es gibt mehrere Varianten des Laplace-Kernels. Verwende nur die Werte 0, 1 und -4 für den Kernel.\n",
    "\n",
    "Weitere Informationen:\n",
    "- Der diskrete Laplace-Kernel wird in der Bildverarbeitung verwendet, um Kanten und Regionen mit starken Intensitätsänderungen zu identifizieren.\n",
    "- Er basiert auf der Berechnung der zweiten Ableitung eines Bildes, wodurch Übergänge und Kontraste hervorgehoben werden.\n",
    "- Das Zentrum des Kerns erhält eine stärkere Gewichtung, die gleich der negativen Summe der Gewichte der umliegenden Elemente ist.\n",
    "- Die benachbarten Werte repräsentieren die unmittelbare Umgebung des zentralen Pixels und ermöglichen eine differenzierte Betrachtung lokaler Unterschiede.\n",
    "- Dieser Kernel hebt Bereiche mit plötzlichen Intensitätsänderungen hervor, indem er die Differenz zwischen dem zentralen Pixel und seinen Nachbarn analysiert.\n",
    "\n",
    "Referenz: https://en.wikipedia.org/wiki/Discrete_Laplace_operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "543747eb1db5e930ae2086bfeeb35b6e",
     "grade": false,
     "grade_id": "cell-20f1ed008daa7518",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def laplacian_edge_detection(im: np.array):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5783621e6134d860525803b8a5779edc",
     "grade": true,
     "grade_id": "Ex_1_2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "# ID: Ex_1_2 - possible points: 1\n",
    "\n",
    "# Tests for 1.2:\n",
    "test_sample_image = np.eye(500, dtype=np.uint8)\n",
    "test_convolved_image = laplacian_edge_detection(test_sample_image)\n",
    "\n",
    "assert test_convolved_image.sum() == -4\n",
    "\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0467a9bc8c84b31fa5d02355ac967477",
     "grade": false,
     "grade_id": "cell-a8295f68a2ebb8fe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In der folgenden Zelle haben wir einige Beispielvisualisierungen vorbereitet.\n",
    "\n",
    "Wir wenden den Laplace-Filter sowohl auf das Graustufenbild als auch auf die separaten Farbkanäle (z. B. Rot, Grün, Blau) des Bildes an. Bei korrekter Implementierung sollte ein Unterschied in den gefilterten Bildern erkennbar sein, abhängig davon, welcher Farbkanal gewählt wurde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply laplacian edge detection to grayscale image\n",
    "lapl_edges = laplacian_edge_detection(gray_test_image)\n",
    "vis_filter_pics(lapl_edges, gray_test_image, title=\"Laplacian Edges on Grayscale\")\n",
    "\n",
    "# Apply laplacian edge detection to each color channel\n",
    "for i in range(test_image.shape[-1]):\n",
    "    # Produce single-channel image for visualization\n",
    "    single_channel_image = np.zeros_like(test_image)\n",
    "    single_channel_image[:, :, i] = test_image[:, :, i]\n",
    "    \n",
    "    # Apply edge detection to only one of the three channels\n",
    "    lapl_edges = laplacian_edge_detection(test_image[:, :, i])\n",
    "\n",
    "    vis_filter_pics(lapl_edges, single_channel_image, title=f\"Laplacian Edges on Channel {i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2ed5910d8c461fbfd96fbfc3ce7eed30",
     "grade": false,
     "grade_id": "cell-ed7711111a07502b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 2. Image Classification mit CNNs\n",
    "In dieser Aufgabe wollen wir verschiedene Hunde- und Katzenarten klassifizieren. Wir verwenden den \"Oxford Pet Datensatz\", welcher aus 37 Klassen besteht, jede Klasse eine andere Katzen/Hundeart. Wir vergleichen 3 verschiedene Architekturen: \n",
    "- Ein Multilayer Perceptron (MLP) \n",
    "- Ein simples CNN\n",
    "- Ein komplexes und großes ResNet, für welches wir Transfer Learning verwenden\n",
    "\n",
    "Zunächst laden wir den Datensatz herunter und analysieren ihn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "dfCiuJRDz0y9",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6affb622ad4a8c7fa671ad776bf5aeaa",
     "grade": false,
     "grade_id": "cell-03243a8236fab050",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.init\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "from collections import defaultdict\n",
    "from typing import Tuple\n",
    "from PIL import Image\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c3c6e01ab55630d65cf8bb187fdd6bf1",
     "grade": false,
     "grade_id": "cell-a1ac5e9f27cdbf72",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "# Downloading the dataset, only if it does not exist already\n",
    "if os.path.isdir(\"oxford_pet\"):\n",
    "    print(\"Dataset already downloaded\")\n",
    "else:\n",
    "    print(\"Downloading dataset\")\n",
    "\n",
    "    # URLs for the dataset\n",
    "    images_url = \"https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\"\n",
    "    annotations_url = \"https://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz\"\n",
    "\n",
    "    # File paths\n",
    "    images_tar = \"oxford_pet_dataset.tar.gz\"\n",
    "    annotations_tar = \"oxford_pet_annotations.tar.gz\"\n",
    "    \n",
    "    # Download the dataset\n",
    "    print(\"Downloading images...\")\n",
    "    urllib.request.urlretrieve(images_url, images_tar)\n",
    "    print(\"Downloading annotations...\")\n",
    "    urllib.request.urlretrieve(annotations_url, annotations_tar)\n",
    "\n",
    "    # Create the dataset directory\n",
    "    os.makedirs(\"oxford_pet\", exist_ok=True)\n",
    "\n",
    "    # Extract the dataset\n",
    "    print(\"Extracting images...\")\n",
    "    with tarfile.open(images_tar, \"r:gz\") as tar:\n",
    "        tar.extractall(path=\"oxford_pet\")\n",
    "\n",
    "    print(\"Extracting annotations...\")\n",
    "    with tarfile.open(annotations_tar, \"r:gz\") as tar:\n",
    "        tar.extractall(path=\"oxford_pet\")\n",
    "\n",
    "    print(\"Dataset downloaded and extracted successfully\")\n",
    "\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ol9MtcPs1vV4",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2a716c16528e40b25c180b98f22f5f8a",
     "grade": false,
     "grade_id": "cell-89b35a04df79f441",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "# Torch Dataset class. Parsing the structure of the provided dataset. Not too important to understand everything.\n",
    "# Also, we downscale the images to 100x100 pixels.\n",
    "\n",
    "class OxfordPetDataset(Dataset):\n",
    "    def __init__(self, images_dir, annotations_dir, target_size=(100, 100)):\n",
    "        self.images_dir = images_dir\n",
    "        self.annotations_dir = annotations_dir\n",
    "        self.image_files = sorted(os.listdir(images_dir))\n",
    "        # remove all non jpg extensions files\n",
    "        self.image_files = [f for f in self.image_files if f.endswith('.jpg')]\n",
    "        self.target_size = target_size\n",
    "        self.transform = transforms.Compose([\n",
    "          transforms.Resize(self.target_size),\n",
    "          transforms.ToTensor(),\n",
    "        ])\n",
    "        self.all_labels = []\n",
    "        self.filtered_image_files = []\n",
    "        self.animal_names = set()\n",
    "        with open(os.path.join(annotations_dir, \"list.txt\"), \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "            for image_file in self.image_files:\n",
    "                animal_name = image_file[:image_file.rfind(\"_\")]\n",
    "                self.animal_names.add(animal_name)\n",
    "                for line in lines:\n",
    "                    found_label = False\n",
    "                    if animal_name in line:\n",
    "                        label = int(line.split()[-3]) - 1\n",
    "                        self.all_labels.append(label)\n",
    "                        self.filtered_image_files.append(image_file)\n",
    "                        found_label = True\n",
    "                        break\n",
    "                if not found_label:\n",
    "                    print(f\"No label found for {image_file}\")\n",
    "        self.image_files = self.filtered_image_files\n",
    "        self.animal_names = list(self.animal_names)\n",
    "        self.animal_names = [x.lower() for x in self.animal_names]\n",
    "        self.animal_names.sort()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get image and corresponding annotation\n",
    "        img_file = self.image_files[idx]\n",
    "        img_path = os.path.join(self.images_dir, img_file)\n",
    "        label = self.all_labels[idx]\n",
    "        # Load image and bounding boxes\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "\n",
    "# Create the dataset\n",
    "images_path = \"oxford_pet/images\"\n",
    "annotations_path = \"oxford_pet/annotations\"\n",
    "dataset = OxfordPetDataset(images_dir=images_path, annotations_dir=annotations_path, target_size=(100, 100))\n",
    "# Define dataset split lengths\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(0.8 * dataset_size)  # 80% for training\n",
    "test_size = dataset_size - train_size  # 20% for testing\n",
    "animal_names = dataset.animal_names\n",
    "\n",
    "\n",
    "# Perform the split\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "train_dataset.animal_names = dataset.animal_names  # subset does not copy attributes\n",
    "test_dataset.animal_names = dataset.animal_names\n",
    "\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "87429f61f6ea5faa098572e64d2a4eba",
     "grade": false,
     "grade_id": "cell-4adf1b50ade58d1c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.1 Class Histogram (1 Punkt)\n",
    "Zunächst wollen wir quantitativ den Datensatz untersuchen: Wie viele Beispiele gibt es pro Klasse? Falls eine Klasse deutlich mehr Beispiele enthält als andere, kann dies zu einem ungewünschten Bias führen.\n",
    "\n",
    "Vervollständige dazu die Funktion `class_distribution` in der nächsten Zelle. Die Funktion erhält ein Pytorch-Dataset, sowie eine Liste von Namen der Klassen. \n",
    "Die Funktion soll ein Dictionary zurück geben, welches als Keys die Klassennamen hat, und als Values die Anzahl an Bildern dieser Klasse im Datensatz. \n",
    "\n",
    "*Hinweis:* \n",
    "- Iteriere über das Dataset. Das zurückgegebene Label ist ein Integer `idx`, der zugehörige Name der Klasse ist dementsprechend `animal_names[idx]`. \n",
    "- Du kannst `defaultdict` verwenden (https://www.geeksforgeeks.org/defaultdict-in-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f0861725b65c9e9ed986a0422655c67d",
     "grade": false,
     "grade_id": "cell-89f8f17a05bedf74",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def class_distribution(dataset: Dataset, animal_names: list) -> dict[str, int]:\n",
    "    \"\"\"\n",
    "    Params:\n",
    "    - dataset: Pytorch Dataset class. \n",
    "    - animal_names: List of all class names.\n",
    "    \n",
    "    Returns: Dictionary with class names as strings and number of occurences in the dataset as values.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2aab758572ff583bff13f06c0e3973c2",
     "grade": false,
     "grade_id": "cell-7abf5286cf32e719",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.2 Class Statistics (1 Punkt)\n",
    "Vervollständige nun die Funktion `class_statistics`, welche ein Tupel aus 2 Integern zurückgeben soll: die Bildanzahl der kleinsten Klasse und die Bildanzahl der größten Klasse. (Hierbei meinen wir mit kleinster/größter Klasse die Klasse mit den wenigsten/meisten Bildern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "994940d1cfb3ab4e11dca897e593511e",
     "grade": false,
     "grade_id": "cell-b0c8097a44dd66d7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def class_statistics(class_occurences: dict[str, int]) -> Tuple[int, int]:\n",
    "    \"\"\"\n",
    "    Params:\n",
    "    - class_occurences: Output of the class_distribution function\n",
    "    \n",
    "    Returns: The minimum and the maximum class size in the dataset. \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6342b924c956412661059878a164c5c5",
     "grade": false,
     "grade_id": "cell-27b70e304a8487bc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "# Plotting of the class histogram\n",
    "class_occurences = class_distribution(train_dataset, animal_names)\n",
    "# Extract keys and values from the dictionary\n",
    "keys = list(class_occurences.keys())\n",
    "values = list(class_occurences.values())\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(8, 6))  \n",
    "plt.bar(keys, values, color='skyblue')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Oxford Pet Class Histogram', fontsize=16)\n",
    "plt.xlabel('Classes', fontsize=12)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Images in Class', fontsize=12)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "stats = class_statistics(class_occurences)\n",
    "print(f\"Min class size: {stats[0]}\")\n",
    "print(f\"Max class size: {stats[1]}\")\n",
    "\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "23aeb807b1428ba948576baac2095477",
     "grade": false,
     "grade_id": "cell-946d8ea62224638b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Wie wir sehen, ist der Datensatz relativ ausgeglichen. Kleinere Unterschiede sind zwar vorhanden, aber das Modell sollte davon nur wenig bis gar nicht beeinflusst werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1262d8a2db355776552e72d91212b753",
     "grade": true,
     "grade_id": "Ex_2_1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "# ID: Ex_2_1 - possible points: 1\n",
    "\n",
    "# Tests for 2.1:\n",
    "class_occurences = class_distribution(train_dataset, animal_names)\n",
    "assert isinstance(class_occurences, dict)\n",
    "assert len(class_occurences) == 37 # numbers of classes present in the dataset\n",
    "\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f58ce1427b3e3685fb5cdb8a12228691",
     "grade": true,
     "grade_id": "Ex_2_2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "# ID: Ex_2_2 - possible points: 1\n",
    "\n",
    "# Tests for 2.2\n",
    "stats = class_statistics(class_occurences)\n",
    "assert isinstance(stats, Tuple)\n",
    "assert isinstance(stats[0], int)\n",
    "assert isinstance(stats[1], int)\n",
    "\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0ac880e68f7359c8f9cf23174ba2a7a9",
     "grade": false,
     "grade_id": "cell-48f6ca1948d494a8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Qualitative Analyse (keine Punkte)\n",
    "Um einen besseren Eindruck zu bekommen, welche Bilder der Datensatz enthält, plotten wir eine Stichprobe des Datensatzs mit den jeweiligen Klassennamen. Wenn ihr die nächste Zelle mehrmals ausführt, erhaltet ihr jeweils eine neue zufällige Stichprobe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 762
    },
    "deletable": false,
    "editable": false,
    "id": "gpjr9aFE36r0",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4585f28368a89a2a92d4107b28cb6616",
     "grade": false,
     "grade_id": "cell-24ad4e66846397bb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "bfcca798-84e5-4a7a-c11c-81e104c9d3d3"
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "# Create a function to display images\n",
    "def show_images(dataset, num_images=16):\n",
    "    # Create a DataLoader for easier batch loading\n",
    "    dataloader = DataLoader(dataset, batch_size=num_images, shuffle=True)\n",
    "\n",
    "    # Load one batch of data\n",
    "    images, labels = next(iter(dataloader))\n",
    "    label_names = dataset.animal_names\n",
    "    # Denormalize and plot the images in a grid\n",
    "    grid = make_grid(images, nrow=4, padding=2)  # 4x4 grid of images\n",
    "    np_grid = grid.numpy()\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(np.transpose(np_grid, (1, 2, 0)))  # Change from CHW to HWC\n",
    "    plt.title(\"Sample Images from Pet3 Dataset\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    print(\"Labels:\")\n",
    "    for i in range(len(labels) // 4):\n",
    "        result = \"\"\n",
    "        for j in range(4):\n",
    "            result += f\"{label_names[labels[i * 4 + j].item()]: <32} \"\n",
    "        print(result)\n",
    "\n",
    "\n",
    "show_images(train_dataset)\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3dbd31e4b4c007d7d496d6d41b6d9c73",
     "grade": false,
     "grade_id": "cell-fad649aaba52af6b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.3 Baseline MLP Implementierung (2 Punkte)\n",
    "\n",
    "Als erstes Modell wollen wir ein Standard Feedforward Netzwerk/MLP implementieren. \n",
    "Dazu werden die Bilder mit shape (3, 100,100) (da 3 Channel RGB) als ein langes Array interpretiert mit `input_shape=100*100*3`.\n",
    "Das Netzwerk soll folgende Layers enthalten:\n",
    "- ein Linear Layer, welches Tensoren von Größe `input_size` auf Tensoren der Größe `512` abbildet.\n",
    "- eine ReLU Activation\n",
    "- ein Linear Layer, welches Tensoren von Größe `512` auf Tensoren der Größe `256` abbildet.\n",
    "- eine ReLU Activation\n",
    "- ein Linear Layer, welches Tensoren von Größe `256` auf Tensoren der Größe `num_classes` abbildet.\n",
    "\n",
    "Implementiere diese Struktur, indem du die Liste `layers` korrekt befüllst. \n",
    "\n",
    "Implementiere anschließend den Forward Pass durch das Netzwerk. \n",
    "\n",
    "*Hinweis:* Im Forward Pass ist `x` ein Tensor mit Größe `(batch_size, 3, 100, 100)` Denke daran, zunächst das Bild in einen Tensor der Größe `(batch_size, 100*100*3)` umzuwandeln. Du kannst dafür die Funktion `x.view(...)` verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "acPpLzNn93uw",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "02f9ac9565d6ca6361960740fd834810",
     "grade": false,
     "grade_id": "cell-d2f8a246254efd81",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class BaselineMLP(nn.Module):\n",
    "    def __init__(self, input_size=100*100*3, num_classes=37):\n",
    "        super(BaselineMLP, self).__init__()\n",
    "        # Define a sequential model with fully connected layers\n",
    "        layers = []\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        # Create a Sequential model which you should use in the Forward pass\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        self.mlp_layers = layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4645f85e40d518cb3b7fc53ea277b6a2",
     "grade": true,
     "grade_id": "Ex_2_3a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "# ID: Ex_2_3a - possible points: 1\n",
    "\n",
    "# Test 2.3\n",
    "mlp = BaselineMLP(input_size=100*100*3, num_classes=37)\n",
    "assert len(mlp.mlp_layers) == 5, \"Fehlende oder zu viele Linear-Layers.\"\n",
    "layers = list(mlp.mlp_layers)\n",
    "assert isinstance(layers[0], nn.Linear), \"Fehler im ersten Linear-Layer.\"\n",
    "assert isinstance(layers[1], nn.ReLU), \"Fehlendes ReLU nach dem ersten Layer.\"\n",
    "assert isinstance(layers[2], nn.Linear), \"Fehler im zweiten Linear-Layer.\"\n",
    "assert isinstance(layers[3], nn.ReLU), \"Fehlendes ReLU nach dem zweiten Layer.\"\n",
    "assert isinstance(layers[4], nn.Linear), \"Fehler im dritten Linear-Layer.\"\n",
    "mlp_params = sum(param.numel() for param in mlp.parameters())\n",
    "assert mlp_params == 15501349\n",
    "\n",
    "\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9dcf58163b9c644dc6f445cbaaf44771",
     "grade": true,
     "grade_id": "Ex_2_3b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "# ID: Ex_2_3b - possible points: 1\n",
    "\n",
    "# Hidden tests, do not remove\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7b69517f69f4ab0416fa7a5d73c87acf",
     "grade": false,
     "grade_id": "cell-d4118d86589456a0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.4 Evaluierung (2 Punkte)\n",
    "Bevor wir das erste Modell trainieren, sollten wir uns Gedanken um die Evaluierung machen. Um das MLP Modell mit anderen Modellen zu vergleichen und die Performanz zu testen, muss es auf ungesehenen Testdaten evaluiert werden. 2 Metriken haben sich für Multi-Klassifikationsaufgaben als besonders relevant erwiesen:\n",
    "- Accuracy: Wie viel Prozent der Testbilder wurden korrekt klassifiziert?\n",
    "- Top-5 Accuracy: Wie oft prädiziert das Modell die korrekte Klasse unter den fünf wahrscheinlichsten Vorhersagen? Bei einem Neuronalen Netzwerk erhalten wir als Output ein Tensor mit Scores pro Klasse. Ist die richtige Klasse unter den 5 Klassen mit den höchsten Scores dabei, zählen wir in der Top-5 Accuracy das Bild als richtig klassifiziert.\n",
    "\n",
    "Implementiere beide Metriken für einen Batch von Outputs und Labels. Vervollständige dazu die Funktionen in der nächsten Zelle.\n",
    "\n",
    "*Hinweise:*\n",
    "- `torch.max(...)` (https://pytorch.org/docs/main/generated/torch.max.html) sowie `torch.topk(...)` (https://pytorch.org/docs/stable/generated/torch.topk.html#torch.topk) könnten hier relevant sein. \n",
    "- Beachte, dass beide Tensoren in der Trainingsloop auf der GPU sind. Falls du komplett neue Tensoren (z.B. mittels `example = torch.zero(..)` definierst, rufe `example.to(outputs.device)` auf. Dies schiebt den Tensor auf das gleiche Device wie das Device von `outputs`.\n",
    "- Um aus einem skalarwertigen Tensor `result` ein `int` zu erhalten, verwende die Methode `result.item()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "65f412665bd5d5c856b979d9307b7ae3",
     "grade": false,
     "grade_id": "cell-e6ecc13ce4fbbd3f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_correct_per_batch(outputs: torch.Tensor, labels: torch.Tensor) -> int:\n",
    "    \"\"\"\n",
    "    Given a batch of outputs of the network and ground-truth labels, compute how many of the outputs are predicted \n",
    "    correctly. We define the prediction of the network as the argmax of the outputs. \n",
    "    params:\n",
    "    - outputs: tensor of shape (batch_size, num_classes). contains per image in the batch the predicted scores. \n",
    "            torch dtype: float32\n",
    "    - labels: tensor of shape (batch_size). Contains per image in the batch the index of the correct class. \n",
    "            torch dtype: int64\n",
    "    \n",
    "    Returns: Integer between 0 and batch_size. Returns the number of correctly classified images in the batch.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def get_top_5_correct_per_batch(outputs: torch.Tensor, labels: torch.Tensor) -> int:\n",
    "    \"\"\"\n",
    "    Computes the number of correct predictions in the Top-5 Accuracy metric for a given batch. \n",
    "    The goal is to determine how many samples have their true label included among the top 5 predicted classes ranked by the model's scores.\n",
    "    params:\n",
    "    - outputs: tensor of shape (batch_size, num_classes). contains per image in the batch the predicted scores. \n",
    "            torch dtype: float32\n",
    "    - labels: tensor of shape (batch_size). Contains per image in the batch the index of the correct class. \n",
    "            torch dtype: int64\n",
    "    \n",
    "    Returns: Integer between 0 and batch_size. Returns the number of correctly top-5 classified images in the batch.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "530ab2ba30a1e409e724ec50737062a9",
     "grade": true,
     "grade_id": "Ex_2_4a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "# ID: Ex_2_4a - possible points: 1\n",
    "\n",
    "# Test für 2.4a Accuracy\n",
    "dummy_output = torch.tensor([[2., 1., 3., 4.], \n",
    "                             [0., 0., 1., 0.], \n",
    "                             [-2., 5., 1., 1.], \n",
    "                             [6., 1., 3., 4.], \n",
    "                             [0., 2., 1., 0.], \n",
    "                             [-2., -3., 3., 1.]])\n",
    "dummy_labels = torch.tensor([3, 3, 1, 2, 1, 2])  # right, wrong, right, wrong, right, right -> Result should be 4\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# put to GPU if available\n",
    "dummy_output = dummy_output.to(device)\n",
    "dummy_labels = dummy_labels.to(device)\n",
    "num_correct = get_correct_per_batch(dummy_output, dummy_labels)\n",
    "assert isinstance(num_correct, int)\n",
    "assert 0 <= num_correct\n",
    "assert num_correct <= len(dummy_labels)\n",
    "assert num_correct == 4\n",
    "\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "80b8dec13f20b568971762a130a2a58f",
     "grade": true,
     "grade_id": "Ex_2_4b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "# ID: Ex_2_4b - possible points: 1\n",
    "\n",
    "# Test für 2.4b top5\n",
    "dummy_output = torch.tensor([[0.,1,2,3,4,5,6,7,8,9], \n",
    "                             [0.,1,2,3,4,5,6,7,8,9], \n",
    "                             [0.,1,2,3,4,5,6,7,8,9],\n",
    "                             [0.,1,2,3,4,5,6,7,8,9],\n",
    "                             [0.,1,2,3,4,5,6,7,8,9],\n",
    "                             [0.,1,2,3,4,5,6,7,8,9],\n",
    "                             [0.,1,2,3,4,5,6,7,8,9],\n",
    "                             [0.,1,2,3,4,5,6,7,8,9],\n",
    "                             [0.,1,2,3,4,5,6,7,8,9],\n",
    "                             [0.,1,2,3,4,5,6,7,8,9],\n",
    "                             [9.,8,7,6,5,0,1,2,3,4],\n",
    "                             [9.,8,7,6,5,0,1,2,3,4],\n",
    "                             [9.,8,7,6,5,0,1,2,3,4],\n",
    "                             [9.,8,7,6,5,0,1,2,3,4],\n",
    "                             [9.,8,7,6,5,0,1,2,3,4],\n",
    "                             [9.,8,7,6,5,0,1,2,3,4],\n",
    "                             [9.,8,7,6,5,0,1,2,3,4],\n",
    "                             [9.,8,7,6,5,0,1,2,3,4],\n",
    "                             [9.,8,7,6,5,0,1,2,3,4],\n",
    "                             [9.,8,7,6,5,0,1,2,3,4]])\n",
    "dummy_labels = torch.tensor([0,1,2,3,4,5,6,7,8,9,0,1,2,3,4,5,6,7,8,9]) \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# put to GPU if available\n",
    "dummy_output = dummy_output.to(device)\n",
    "dummy_labels = dummy_labels.to(device)\n",
    "num_correct = get_top_5_correct_per_batch(dummy_output, dummy_labels)\n",
    "assert isinstance(num_correct, int)\n",
    "assert 0 <= num_correct\n",
    "assert num_correct <= len(dummy_labels)\n",
    "assert num_correct == 10\n",
    "\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "25218bbe559e2cac88517f77f45d25e3",
     "grade": false,
     "grade_id": "cell-d5e39945105b742b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Training des MLPs (keine Punkte)\n",
    "Nun können wir unser erstes Modell trainieren. Hierfür verwenden wir den Code in der nächsten Zelle. Der Aufruf ist in der Zelle danach. Nach jeder Epoche evaluieren wir die Accuracy. Außerdem berechnen wir am Ende des Trainings eine Confusion Matrix. Diese zeigt, welche Klassen wie oft für eine andere Klasse verwechselt wurden. Idealerweise sollte diese Matrix eine pefekte Diagonalmatrix sein. Du solltest eine Accuracy von ca. 10-11% erhalten. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e1e4894f4949e60c7970392795dcb1fc",
     "grade": false,
     "grade_id": "cell-04e51213d5752c70",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "def train_and_evaluate(model, num_epochs, device, lr=0.0001):\n",
    "    batch_size = 32\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2) \n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)  # Test loader\n",
    "    print(f\"Using Device: {device}\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()  # Loss function\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)  # Optimizer\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        t0 = time.time()\n",
    "        model.train()  # Set the model to training mode\n",
    "        running_loss = 0.0\n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to device\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate loss\n",
    "            running_loss += loss.item()\n",
    "        t1 = time.time()\n",
    "        # Print epoch statistics\n",
    "        print(f\"------------------------\\nEpoch [{epoch+1}/{num_epochs}] took {t1 - t0:.2f} seconds.\\nTrain Loss: {running_loss / len(train_loader):.4f}\")\n",
    "        evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "\n",
    "def evaluate(model, test_loader, criterion, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    top5_correct = 0\n",
    "    total = 0\n",
    "    total_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculations for evaluation\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to device\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            #torch.set_printoptions(edgeitems=None, linewidth=200, threshold=10000)\n",
    "            #print(\"----------\")\n",
    "            #print(outputs)\n",
    "            #print(labels)\n",
    "            # Update counts\n",
    "            try:\n",
    "                top5_correct += get_top_5_correct_per_batch(outputs, labels)\n",
    "                # print(\"top_5\", top5_correct)\n",
    "            except Exception:\n",
    "                # Something went wrong in the computation of the top_5 computation. Skip this metric.\n",
    "                pass\n",
    "            try:\n",
    "                correct += get_correct_per_batch(outputs, labels)\n",
    "                # print(\"correct\", correct)\n",
    "            except Exception:\n",
    "                # Something went wrong in the computation of the accuracy. Skip this metric.\n",
    "                pass\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "\n",
    "    # Calculate accuracy and average loss\n",
    "    accuracy = 100 * correct / total\n",
    "    top_5_accuracy = 100 * top5_correct / total\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Test Top-5 Accuracy: {top_5_accuracy:.2f}%\")\n",
    "    print(f\"Test Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "def show_images_with_predictions(dataset, model, num_images=16, device='cpu'):\n",
    "    import torch\n",
    "    from torchvision.utils import make_grid\n",
    "    from torch.utils.data import DataLoader\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import math\n",
    "\n",
    "    sqrt_n = math.isqrt(num_images)\n",
    "    num_images = sqrt_n ** 2\n",
    "\n",
    "    # Ensure model is in evaluation mode\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Label names\n",
    "    label_names = dataset.animal_names\n",
    "\n",
    "\n",
    "\n",
    "    # Create a DataLoader for easier batch loading\n",
    "    dataloader = DataLoader(dataset, batch_size=num_images, shuffle=True)\n",
    "\n",
    "    # Load one batch of data\n",
    "    images, labels = next(iter(dataloader))\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "        _, predicted_labels = torch.max(outputs, 1)\n",
    "\n",
    "\n",
    "    # Create grid of images\n",
    "    grid = make_grid(images.cpu(), nrow=sqrt_n, padding=2)  #grid of images\n",
    "    np_grid = grid.numpy()\n",
    "\n",
    "    # Display the images\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(np.transpose(np_grid, (1, 2, 0)))  # Change from CHW to HWC\n",
    "    plt.title(\"Sample Images from Oxford Pet3\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    # Print labels\n",
    "    print(\"Labels (True | Predicted):\")\n",
    "    for i in range(len(labels) // sqrt_n):\n",
    "        result = \"\"\n",
    "        for j in range(sqrt_n):\n",
    "            idx = i * sqrt_n + j\n",
    "            true_label = label_names[labels[idx].item()]\n",
    "            pred_label = label_names[predicted_labels[idx].item()]\n",
    "            result += f\"{true_label[:8]:<10} | {pred_label[:8]:<12} \"\n",
    "        print(result)\n",
    "        \n",
    "def plot_confusion_matrix(dataset, model, names, device):\n",
    "    test_loader = DataLoader(dataset, batch_size=32, shuffle=False)  # Test loader\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    gth = []\n",
    "    pred = []\n",
    "    with torch.no_grad():  # Disable gradient calculations for evaluation\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to device\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            gth.append(labels)\n",
    "            pred.append(predicted)\n",
    "    \n",
    "    gth = torch.cat(gth).cpu().numpy()\n",
    "    pred = torch.cat(pred).cpu().numpy()\n",
    "    \n",
    "    # Get the number of classes\n",
    "    num_classes = len(names)\n",
    "\n",
    "    # Initialize the confusion matrix with zeros\n",
    "    cm = np.zeros((num_classes, num_classes), dtype=int)\n",
    "\n",
    "    # Populate the confusion matrix\n",
    "    for true, pred_label in zip(gth, pred):\n",
    "        cm[true, pred_label] += 1\n",
    "\n",
    "    # Plotting the confusion matrix\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)  # Display the matrix as an image\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "\n",
    "    # Add color bar\n",
    "    plt.colorbar()\n",
    "\n",
    "    # Set tick marks and labels using class names\n",
    "    plt.xticks(np.arange(num_classes), names, rotation=90)\n",
    "    plt.yticks(np.arange(num_classes), names)\n",
    "\n",
    "    # Annotate the cells with the confusion matrix values\n",
    "    for i in range(num_classes):\n",
    "        for j in range(num_classes):\n",
    "            plt.text(j, i, str(cm[i, j]), ha='center', va='center', color='white' if cm[i, j] > cm.max() / 2 else 'black')\n",
    "\n",
    "    # Layout adjustments\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(42)\n",
    "mlp = BaselineMLP(num_classes=37).to(device)\n",
    "# Falls ihr hier etwas ändert, bitte darauf achten, dass diese If-Abfrage nicht entfernt wird.\n",
    "# Ansonsten wird das auto-grading zu lange dauern und abbrechen.\n",
    "if not is_grading:\n",
    "    train_and_evaluate(mlp, num_epochs=10, device=device, lr=0.0001)\n",
    "    plot_confusion_matrix(test_dataset, mlp, animal_names, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qualitative results, restart this cell for different results\n",
    "show_images_with_predictions(test_dataset, mlp, num_images=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "01e1830baa6165f4b50ad54028049048",
     "grade": false,
     "grade_id": "cell-2291744bbd1e3395",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.5 CNN Implementierung (2 Punkte)\n",
    "Nun wollen wir vergleichen, wie gut ein CNN abschneidet. \n",
    "\n",
    "Implementiere den \"Feature Extractor\" Teil, welcher aus folgenden Convolution Layers, Activation Layers und Pooling Layers besteht:\n",
    "- Convolution, in_channels: **3**, out_channels: **32**, kernel_size: **5**, stride: 1, padding: **2**\n",
    "- ReLU Activation \n",
    "- Max Pooling, kernel_size: 2, stride: 2\n",
    "<br>\n",
    "  \n",
    "- Convolution, in_channels: **32**, out_channels: **64**, kernel_size: **3**, stride: 1, padding: **1**\n",
    "- ReLU Activation\n",
    "- Max Pooling, kernel_size: 2, stride: 2\n",
    "<br>\n",
    "  \n",
    "  \n",
    "- Convolution, in_channels: **64**, out_channels: **128**, kernel_size: 3, stride: 1, padding: 1\n",
    "- ReLU Activation\n",
    "- Max Pooling, kernel_size: 2, stride: 2\n",
    "<br>  \n",
    "  \n",
    "  \n",
    "- Convolution, in_channels: **128**, out_channels: **256**, kernel_size: 3, stride: 1, padding: 1\n",
    "- ReLU Activation\n",
    "- Max Pooling, kernel_size: 2, stride: 2\n",
    "\n",
    "Implementiere diese Struktur, indem du die Liste `feature_extractor_layers` korrekt befüllst. \n",
    "\n",
    "Anschließend wird im Forward pass der Output vom Feature Extractor \"flattened\", sodass der resultierende Tensor Shape `(batch_size, 256 * final_img_size * final_img_size)` hat. Überlege, welche Größe `final_img_size` hat. Beachte, dass bei ungeraden Bildgrößen die MaxPool Layer abrundet. Implentiere anschließend die Layers vom Classifier:\n",
    "\n",
    "- Fully Connected, in_features: 256 * final_img_size * final_img_size, out_features: 128\n",
    "- ReLU Activation\n",
    "- Fully Connected, in_features: 128, out_features: `num_classes`\n",
    "\n",
    "Den Forward Pass haben wir bei diesem Netzwerk schon gegeben.\n",
    "\n",
    "*Hinweise:*\n",
    "- Verwende für die Convolutions die Implementierung `torch.nn.Conv2d` (https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html). Lasse nicht gegebene Argumente wie `groups` oder `padding_mode` beim Default Wert.\n",
    "- Verwende für die Max Pooling Layers die Implementierung `torch.nn.MaxPool2d`(https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "iCHF_1xz48BD",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fff755a4c047671ae6f1c7b50610fc15",
     "grade": false,
     "grade_id": "cell-c385614a05d004e9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=37):  \n",
    "        super().__init__()\n",
    "        feature_extractor_layers = []\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        self.feature_extractor = nn.Sequential(*feature_extractor_layers)\n",
    "        self.feature_extractor_layers = feature_extractor_layers\n",
    "        \n",
    "        classifier_layers = []\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        self.classifier = nn.Sequential(*classifier_layers)\n",
    "        self.classifier_layers = classifier_layers\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = torch.flatten(x, 1)  # Flatten feature maps into vectors\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3d59f7a3a7497a0e862b841c307d4225",
     "grade": true,
     "grade_id": "Ex_2_5",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "# ID: Ex_2_5 - possible points: 2\n",
    "\n",
    "# Test für 2.5\n",
    "cnn = CNN(num_classes=37)\n",
    "# ----- Feature Extraction -----\n",
    "assert len(cnn.feature_extractor_layers) == 12, \"Fehlende oder zu viele Feature-Extractor-Layers.\"\n",
    "layers = list(cnn.feature_extractor_layers)\n",
    "assert isinstance(layers[0], nn.Conv2d), \"Fehler im ersten Convolution-Layer.\"\n",
    "assert isinstance(layers[1], nn.ReLU), \"Fehlendes ReLU nach der ersten Convolution.\"\n",
    "assert isinstance(layers[2], nn.MaxPool2d), \"Fehler im MaxPool-Layer nach der ersten Convolution.\"\n",
    "\n",
    "assert isinstance(layers[3], nn.Conv2d), \"Fehler im zweiten Convolution-Layer.\"\n",
    "assert isinstance(layers[4], nn.ReLU), \"Fehlendes ReLU nach der ersten Convolution.\"\n",
    "assert isinstance(layers[5], nn.MaxPool2d), \"Fehler im MaxPool-Layer nach der zweiten Convolution.\"\n",
    "\n",
    "assert isinstance(layers[6], nn.Conv2d), \"Fehler im dritten Convolution-Layer.\"\n",
    "assert isinstance(layers[7], nn.ReLU), \"Fehlendes ReLU nach der ersten Convolution.\"\n",
    "assert isinstance(layers[8], nn.MaxPool2d), \"Fehler im MaxPool-Layer nach der dritten Convolution.\"\n",
    "\n",
    "assert isinstance(layers[9], nn.Conv2d), \"Fehler im vierten Convolution-Layer.\"\n",
    "assert isinstance(layers[10], nn.ReLU), \"Fehlendes ReLU nach der ersten Convolution.\"\n",
    "assert isinstance(layers[11], nn.MaxPool2d), \"Fehler im MaxPool-Layer nach der vierten Convolution.\"\n",
    "\n",
    "# ----- Classifier -----\n",
    "assert len(cnn.classifier_layers) == 3, \"Fehlende oder zu viele Classifier-Layers.\"\n",
    "layers = list(cnn.classifier_layers)\n",
    "assert isinstance(layers[0], nn.Linear), \"Fehler im ersten Linear-Layer.\"\n",
    "assert isinstance(layers[1], nn.ReLU), \"Fehlendes ReLU nach dem ersten Layer.\"\n",
    "assert isinstance(layers[2], nn.Linear), \"Fehler im zweiten Linear-Layer.\"\n",
    "\n",
    "# ------- Total Parameters --------\n",
    "cnn_params = sum(param.numel() for param in cnn.parameters())\n",
    "assert cnn_params == 1574501\n",
    "\n",
    "\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4cf90634826d0e6b1690359ca8ee91db",
     "grade": false,
     "grade_id": "cell-524236384874b299",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Training des CNNs (keine Punkte)\n",
    "Führe die nächste Zelle aus, um das CNN zu trainineren. Du solltest eine höhere Accuracy erhalten als das MLP (Um die 20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JxVyaTlM-5HS"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(42)\n",
    "cnn = CNN(num_classes=37).to(device)\n",
    "# Falls ihr hier etwas ändert, bitte darauf achten, dass diese If-Abfrage nicht entfernt wird.\n",
    "# Ansonsten wird das auto-grading zu lange dauern und abbrechen.\n",
    "if not is_grading:\n",
    "    train_and_evaluate(cnn, num_epochs=10, device=device, lr=0.0001)\n",
    "    plot_confusion_matrix(test_dataset, cnn, animal_names, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qualitative results, restart this cell for different results\n",
    "show_images_with_predictions(test_dataset, cnn, num_images=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "PIVQgrUL6qSN",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "93c43cba5ed86237a7f1f80e420672ae",
     "grade": false,
     "grade_id": "cell-8561ad07d3fbc629",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.6 Fine-Tuning eines ResNets ( 1 Punkt)\n",
    "Obwohl die Performance des CNNs besser ist als die des MLPs, ist die maximale Top-5 Accuracy des CNNs nur bei ca. 50%. Längeres Training könnte hier helfen, allerdings wird dann die Gefahr von Overfitting größer. Um den Task gut zu lösen, benötigen wir mehr Daten und größere Netzwerke. Deshalb wollen wir in dieser letzten Aufgabe ein ResNet mithilfe von Fine-Tuning trainieren.\n",
    "\n",
    "Pytorch hat eine größere Ansammlung an Modellen, welche auf größeren Datensätzen (bspw. ImageNet: https://de.wikipedia.org/wiki/ImageNet) vortrainiert wurden. \n",
    "Wir können solch ein Modell und dessen vortrainierten Gewichte laden, und anschließend die letzte Layer anpassen, sodass das Modell Vorhersagen für unser Datensatz mit 37 unterschiedlichen Klassen macht.\n",
    "\n",
    "Vervollständige dazu die Funktion `get_resnet`, welche ein vortrainiertes ResNet lädt und anschließend die letzte Layer anpassen soll.\n",
    "\n",
    "*Hinweise:*\n",
    "- Die letzte Layer des ResNets ist gespeichert unter `resnet.fc`. Ersetze diese durch ein `torch.nn.Linear` Layer mit korrekten `in_features` und `out_features`. \n",
    "- Die ursprünglichen `in_features` erhältst du über `resnet.fc.in_features`, bevor du die Layer ersetzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "59f9aead2aa6a951e8cd250116973348",
     "grade": false,
     "grade_id": "cell-9e52efbc6c58a4e1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_resnet(num_classes=37):\n",
    "    resnet = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.IMAGENET1K_V1)  # load the resnet with pretrained weights\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b6005cf88611054773046987e19b2fb6",
     "grade": true,
     "grade_id": "Ex_2_6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "# ID: Ex_2_6 - possible points: 1\n",
    "\n",
    "# Tests für 2.6\n",
    "resnet = get_resnet(num_classes=37)\n",
    "assert isinstance(resnet, torchvision.models.ResNet)\n",
    "assert hasattr(resnet, \"fc\")\n",
    "assert isinstance(resnet.fc, nn.Linear)\n",
    "assert resnet.fc.out_features == 37\n",
    "\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6de67082dc8a5b694a48b60eb083f7dd",
     "grade": false,
     "grade_id": "cell-2ab1e6ce5691f102",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Training des ResNets (keine Punkte)\n",
    "Führe die nächste Zelle aus, um das ResNet zu trainineren. Die Accuracy sollte nun extrem viel höher sein, ca. bei 80%!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a0lODTcM61Yk"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(42)\n",
    "resnet = get_resnet(num_classes=37).to(device)\n",
    "# Falls ihr hier etwas ändert, bitte darauf achten, dass diese If-Abfrage nicht entfernt wird.\n",
    "# Ansonsten wird das auto-grading zu lange dauern und abbrechen.\n",
    "if not is_grading:\n",
    "    train_and_evaluate(resnet, num_epochs=10, device=device, lr=0.00001)  # smaller lr for finetuning\n",
    "    plot_confusion_matrix(test_dataset, resnet, animal_names, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qualitative results, restart this cell for different results\n",
    "show_images_with_predictions(test_dataset, resnet, num_images=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "32e933b5c09fca14f379ae0af84de625",
     "grade": false,
     "grade_id": "cell-732922d3a5664e59",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Zusammenfassung\n",
    "Dies war das Notebook über CNNs. Wenn man eines mitnehmen möchte, dann dass Transfer Learning die Performance extrem verbessern kann. Allerdings waren bei uns die Aufgaben auch ähnlich (die Modelle wurden auch auf Multi-Klassifikation vortrainiert, insbesondere auf tausenden verschiedenen Tierklassen), deshalb kann man solch eine Verbesserung nicht immer erwarten. Da das Interface von Pytorch allerdings so einfach ist um vortrainierte Modelle zu laden, lohnt es sich auf jeden Fall es auszuprobieren.\n",
    "\n",
    "Vergesst nicht die Theorie Aufgabe auf dem Übungsblatt!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
