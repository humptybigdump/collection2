{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exkurs: Training eines künstlichen neuronalen Netzes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hintergrund und Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der hier verwendete Datensatz heißt MNIST und stammt von dieser Website: http://yann.lecun.com/exdb/mnist/.\n",
    "\n",
    "Die Datei <b>mnist_data.npz</b> enthält die Matrizen $X\\in\\mathbb{R}^{60000\\times 784}$, $Y\\in\\mathbb{R}^{60000\\times 10}$, $X_t\\in\\mathbb{R}^{10000\\times 784}$ und $Y_t\\in\\mathbb{R}^{10000\\times 10}$. \n",
    "\n",
    "Die Matrizen $X$ und $Y$ enthalten den Datensatz, den Sie für die Optimierung verwenden sollen. In den Zeilen der Matrix $X$ stehen die Vektoren $x^i$. In den Zeilen von $Y$ sind die zugehörige Vektoren $y^i$ gespeichert. Dieser Datensatz besteht also aus $n=60000$ Datenpunkten.\n",
    "\n",
    "Die Matrizen $X_t\\in\\mathbb{R}^{10000\\times 784}$ und $Y_t\\in\\mathbb{R}^{10000\\times 10}$ enthalten den Test-Datensatz. Es gilt ganz analog: In den Zeilen der Matrix $X_t$ stehen die Test-Vektoren $x^i_t$. In den Zeilen von $Y_t$ sind die zugehörige Vektoren $y^i_t$ gespeichert. Der Test-Datensatz besteht also aus $10000$ Datenpunkten.\n",
    "\n",
    "Der Datensatz kann folgendermaßen geladen werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.load(\"mnist_data.npz\")\n",
    "X = data['X']\n",
    "Y = data['Y']\n",
    "X_t = data['X_t']\n",
    "Y_t = data['Y_t']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die mit den Vektoren $x^i$ kodierten Bilder können sehr einfach visualisiert werden. Wir schauen uns exemplarisch die 111. Zahl an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "i = 111\n",
    "plot_array = X[i,:].reshape((28,28))\n",
    "matplotlib.pyplot.imshow(plot_array, cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im zugehörigen Vektor $y^i$ ist die Information gespeichert, dass es sich um die Ziffer 3 handelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y[i,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Die Funktionen in MLP.py\n",
    "In der Python-Datei <b>MLP.py</b> finden Sie die Python-Funktionen <b>F</b>, <b>F_gradient</b> und <b>h</b>, welche die Zielfunktion $F$, ihren Gradienten $\\nabla F$ und die Prognosefunktion $h$ implementieren. (Sie müssen diese also nicht selbst implementieren.)\n",
    "\n",
    "Damit Sie die Python-Funktionen in der Datei <b>MLP.py</b> in diesem Jupyter-Notebook verwenden können, werden die Inhalte der Datei importiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MLP import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beachten Sie: Die Zielfunktion <b>F</b> wird für einen festen Trainingsdatensatz über die Parameter des neuronalen Netzes minimiert. Das heißt, in einem Lösungsverfahren werden <b>F</b> und <b>F-gradient</b> immer für verschiedene Parameter-Vektoren $w\\in \\mathbb{R}^d$ ausgewertet, der Trainingsdatensatz <b>X</b> und <b>Y</b> ist fest. \n",
    "\n",
    "Passen Sie daher die Aufrufstruktur mithilfe von lambda-Funktionen an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_val = lambda ... #TODO\n",
    "F_grad = lambda ... #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die definierten lambda-Funktionen können an einem Parametervektor $w\\in \\mathbb{R}^d$ ausgewertet werden. Wir können hierbei feststellen, dass die Auswertung recht aufwändig ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 79510 # Anzahl der Parameter im Netzwerk\n",
    "w_bar = 0.05 * np.random.randn(d) # Zufallsvektor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "F_val(w_bar)\n",
    "print(\"Die Auswertung der Zielfunktion an w_bar benötigt {:.{prec}f} Sekunden\".format(time.time()-start,prec=2))\n",
    "start = time.time()\n",
    "F_grad(w_bar)\n",
    "print(\"Die Auswertung des Gradienten an w_bar benötigt {:.{prec}f} Sekunden\".format(time.time()-start,prec=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimierung mit Gradientenverfahren "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementieren Sie hier das Gradientenverfahren mit Armijo-Schrittweitensteuerung. \n",
    "\n",
    "Beachten Sie, dass in dieser Anwendung die Auswertung des Gradienten `F_grad` und der Zielfunktion `F_val` recht aufwändig ist. Passen Sie die Methoden daher so an, dass möglichst wenige Auswertungen benötigt werden.\n",
    "\n",
    "Ergänzen Sie ein Zeitlimit, das dem Gradientenverfahren übergeben wird. Die Ausführung der while-Schleife wird beendet, wenn das Zeitlimit überschritten wird. Die Länge des Gradienten von F soll für den Abbruch des Verfahrens keine Rolle spielen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def gradientDescent_timelimit(obj_func, grad_func, line_search, x_0, T):\n",
    "    \"\"\" classical gradient descent with timelimit\n",
    "    \"\"\"\n",
    "    ... # TODO\n",
    "    return x_crit, f_crit, k\n",
    "\n",
    "def armijo_gd(x, d, obj_func, sigma, rho, gamma):\n",
    "    \"\"\" Armijo stepsize for gradient descent\n",
    "    \"\"\"\n",
    "    ... # TODO\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Startpunkte und Aufruf der Methode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Verfahren werden mit 5 (pseudo-)zufälligen Startpunkten $w^0$ gestartet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = 5                                 \n",
    "w_0 = np.zeros([runs,d])                 # \"Platzhalter\", Startvektoren Nr. i steht in der i-ten Zeile von w_0\n",
    "np.random.seed(123)                      # Setzt den Seed des Zufallszahlengenerators auf 123\n",
    "for k in range(runs):                   \n",
    "    w_0[k,:] = 0.05 * np.random.randn(d) # Ein neuer \"zufälliger\" Startpunkt für jeden Durchlauf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berechnen Sie für die Startpunkte eine Approximation eines kritischen Punktes der Funktion F mithilfe des zuvor beschriebenen Gradientenverfahrens. Für jeden Startpunkt soll das Verfahren 180 Sekunden laufen. Die Armijo-Parameter sind unten angegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramter Gradientenverfahren\n",
    "Timelimit = 180\n",
    "# Parameter Armijo-Regel\n",
    "sigma = 0.2\n",
    "rho = 0.5\n",
    "gamma = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambda-Funktion zur Übergabe an der Armijo-Regel an das Gradientenverfahren\n",
    "armijo_rule_gd = lambda ... # TODO\n",
    "\n",
    "# Platzhalter Outputs\n",
    "w_k = np.zeros([runs,d])\n",
    "F_k = np.zeros(runs)\n",
    "it_k = np.zeros(runs)\n",
    "\n",
    "# Optimierung von jedem Startpunkt\n",
    "for k in range(runs):\n",
    "    w_k[k,:], F_k[k], it_k[k] = ... # TODO\n",
    "\n",
    "# Speichern des Ergebnisses\n",
    "key_gdc = \"sol_gdc_{0}_{1}\"\n",
    "np.savez(key_gdc.format(Timelimit,runs),w_k=w_k,F_k=F_k,it_k=it_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auswertung der Ergebnisse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun sollen Sie die Frage beantworten, wie viel Prozent der Bilder des Test-Datensatzes (<b>$X_t$, $Y_t$</b>) im Mittel korrekt erkannt werden, wenn die Prognosefunktionen verwendet werden, die sich aus den mit dem jeweiligen Verfahren berechneten Punkten ergeben. Was heißt in diesem Kontext \"korrekt erkannt\"? \n",
    "\n",
    "Ein Beispiel: Seien $x\\in\\mathbb{R}^{784}$ ein Punkt des Test-Datensatzes und $y$ das zugehörige Label. Dann sagen wir, dass das Bild $x$ bei Wahl des Punktes/Parameters $w\\in\\mathbb{R}^d$ (aus der vorigen Aufgabe!) korrekt erkannt wird, wenn der Index des größten Eintrags des Vektors $h(x;w)$ mit dem einzigen Nicht-Null-Eintrag von $y$ übereinstimmt, d.h. für $i\\in\\arg\\!\\max h(x;w)$ muss $y_i=1$ gelten.\n",
    "\n",
    "Wenn Sie die Funktion $h$ mit\n",
    "\n",
    "`Y_pred = h(w, X_t)`\n",
    "\n",
    "aufrufen, enthält die Matrix <b>Y_pred</b> die Vorhersagen für jeden Punkt des Test-Datensatzes bei Wahl des Parameters <b>w</b>. Sie müssen diese Matrix dann wie oben beschrieben mit der gegebenen Matrix <b>Y_t</b> abgleichen, um herauszufinden, wie viel Prozent der Vorhersagen zutreffen. Dies wiederholen Sie dann für jeden der zuvor berechneten Parametervektoren. Geben Sie anschließend das arithmetische Mittel und die empirische Standardabweichung an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten aus Testlauf wieder laden\n",
    "key_gdc = \"sol_gdc_{0}_{1}\"\n",
    "data = np.load(key_gdc.format(Timelimit,runs)+\".npz\")\n",
    "w_k = data['w_k']\n",
    "F_k = data['F_k']\n",
    "it_k = data['it_k']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe der Zielfunktionswerte der approximierten Punkte\n",
    "... # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnung der Prognosegenauigkeit\n",
    "... # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konjugierte Gradientenverfahren von Fletcher-Reeves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementieren Sie nun das CG-Verfahren von Fletcher Reeves mit Armijo-Schrittweitensteuerung. \n",
    "\n",
    "Das Verfahren soll ebenfalls nach einem gesetzten Zeitlimit abbrechen. Achten Sie wieder darauf nur so viele Auswertungen des Gradienten und der Zielfumktion wie nötig zu berechnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CG_FR_timelimit(obj_func, grad_func, line_search, x_0, T):\n",
    "    \"\"\" nonlinear conjugate gradient method of Fletcher-Reeves\n",
    "    \"\"\"\n",
    "    ... # TODO\n",
    "    return x_opt, f_opt, k\n",
    "\n",
    "def armijo(x, d, gradient_at_x, obj_func, sigma, rho, gamma):\n",
    "    \"\"\" Armijo stepsize\n",
    "    \"\"\"\n",
    "    ... # TODO\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Führen Sie für das CG-Verfahren nun die gleichen Schritte aus, wie für das Gradientenverfahren und vergleichen Sie die Ergebnisse. Die Parameter sind nachfolgend angegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter CG\n",
    "Timelimit = 180\n",
    "# Paramter Armijo\n",
    "sigma = 0.2\n",
    "rho = 0.5\n",
    "gamma = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lambda-Funktion zur Übergabe an der Armijo-Regel an das CG-Verfahren\n",
    "armijo_cg = lambda ... # TODO\n",
    "\n",
    "# Platzhalter für die Outputs\n",
    "w_k = np.zeros([runs,d])\n",
    "F_k = np.zeros(runs)\n",
    "it_k = np.zeros(runs)\n",
    "\n",
    "# Optimierung von jedem Startpunkt\n",
    "for k in range(runs):\n",
    "    w_k[k,:], F_k[k], it_k[k] = ... # TODO\n",
    "\n",
    "# Speichern des Ergebnisses\n",
    "key_cg = \"sol_cg_{0}_{1}\"\n",
    "np.savez(key_cg.format(Timelimit,runs), w_k=w_k, F_k=F_k, it_k=it_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten aus Testlauf wieder laden\n",
    "key_cg = \"sol_cg_{0}_{1}\"\n",
    "data = np.load(key_cg.format(Timelimit,runs)+\".npz\")\n",
    "w_k = data['w_k']\n",
    "F_k = data['F_k']\n",
    "it_k = data['it_k']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe der Zielfunktionswerte der approximierten Punkte\n",
    "... # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnung der Prognosegenauigkeit \n",
    "... # TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
