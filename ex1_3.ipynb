{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exercise 1, Mini Image Classifier, 28P(oints)\n",
    "\n",
    "## Lab Instructions\n",
    "All your answers of this exercise should be written **in this notebook**.\n",
    "You shouldn't need to write or modify any other files.\n",
    "\n",
    "**You should execute every block of code to not miss any dependency. For the\n",
    "training tasks, your notebook should contain the classification accuracy (the\n",
    " figures are NOT necessary however).\n",
    " Please DO NOT clear the notebook output when you submit it.\n",
    " Please DO NOT upload the dataset when you submit your homework.**\n",
    "\n",
    "This exercise was developed by Ge Li for the KIT Cognitive Systems Lecture,\n",
    "July 2021.\n",
    "\n",
    "## Task instructions:\n",
    "In this jupyter notebook, you are going to define multiple **Image\n",
    "classifiers** with different structures. Read the instruction and example code\n",
    "carefully and finish the tasks. You can run the training procedure and\n",
    "thereby verify your computation and implementation.<br>\n",
    "\n",
    "Detailed instructions:\n",
    "\n",
    "0. You need to install torch and torchvision to run this notebook. E.g. if you\n",
    " use pip as the package manager, run \"pip3 install torch torchvision\".\n",
    "  You need to install tqdm for visualize process-bar and matplotlib to visualize\n",
    " figure, run \"pip3 install tqdm matplotlib\".  \n",
    " You do not need a GPU to train.<br><br>\n",
    "\n",
    "1. The dataset you are working with is CIFAR-10 dataset. The code in the file\n",
    "**data_loader.py** will download and manage this dataset for you. You do not\n",
    " need to write any code for it.<br><br>\n",
    "\n",
    "2. The deep learning platform you are working with is PyTorch. In the scope of\n",
    "this homework, you can learn the fundamental knowledge from the instructions.\n",
    " You don't have to spend much time on external materials / tutorials.<br><br>\n",
    "\n",
    "3. In this notebook, you will focus on the Neural Network models for image\n",
    "classification. A classifier with fully connected layers is given as an\n",
    "example. This example mainly contains two parts: a **constructor** in which\n",
    "all the layers to be used are initialized (except activation function), and a\n",
    "**forward** function, where\n",
    "forward pass process of the network is defined. In PyTorch, once the forward\n",
    "function of a network is\n",
    "given, the gradient of the loss function with respect to the network\n",
    "parameters can be automatically computed and back-propagated.<br><br>\n",
    "\n",
    "4. In your model's constructor, you may need to call these functions:\n",
    "    - Define fully connected layers: **nn.Linear(in_features, out_features)**,\n",
    "such as: nn.Linear(64, 10)\n",
    "    - Define 2-D convolutional layers: **nn.Conv2d(in_channels, out_channels,\n",
    "kernel_size, stride, padding)**, such as: nn.Conv2d(8, 16, 5, padding=0)\n",
    "    - Define max-pooling layers: **nn.MaxPool2d(kernel_size, stride)**, such as:\n",
    "nn.MaxPool2d(2, 2)<br><br>\n",
    "\n",
    "5. In your model's forward function, you may need to call these functions:\n",
    "    - Flatten the 3rd order tensor to 1st order tensor: e.g. **x = torch\n",
    "    .flatten(x, 1)**\n",
    "    - Relu activation function: e.g. **x = F.relu(x)**<br><br>\n",
    "\n",
    "6. All the training and plotting related code are offered in the\n",
    "file **fit.py**. The contents can\n",
    "be described in the pseudo code below, which is also a common workflow\n",
    "in deep learning. <br>\n",
    "    - Get train, valid and test data-loader to load data from dataset.\n",
    "    - Initialize the loss function and optimizer for parameters' updating.\n",
    "    - Loop in epochs:\n",
    "        - Loop in batch of training dataset:\n",
    "            - Compute the output using forward function\n",
    "            - Compute the loss using output and labels\n",
    "            - Applying back-propagation and update network parameters\n",
    "            - Record the training loss\n",
    "        - Loop in batch of validation dataset:\n",
    "            - Compute the output using forward function\n",
    "            - Compute the loss using output and labels\n",
    "            - Record the validation loss\n",
    "        - Plotting the training and validation loss for each epoch.\n",
    "        - save model's parameters if the model achieves a better performance\n",
    "        - break the loop (early stopping) if the validation loss keeps\n",
    "        increasing.\n",
    "    - Apply the model with the best parameters to the test dataset and get the\n",
    "    result (classification accuracy).\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6a84c954d34aadb5b2e53a42800916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 9>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnn\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctional\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mF\u001B[39;00m\n\u001B[0;32m----> 9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mex1\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfit\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m fit\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# Fix random seed to make sure the result in your computer is reproducible\u001B[39;00m\n\u001B[1;32m     12\u001B[0m torch\u001B[38;5;241m.\u001B[39mmanual_seed(\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/KIT/teaching/cogsys/kogsys_2022/hw6/yourID-yourName/ex1/fit.py:29\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mex1\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata_loader\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_data_loader\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# Get data loaders\u001B[39;00m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m# data loader is an object used as as an iterator, which can be use in the\u001B[39;00m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;66;03m# for... in loop, such as:\u001B[39;00m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;66;03m#             for data in dataloader:\u001B[39;00m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;66;03m#                 blablabla...\u001B[39;00m\n\u001B[0;32m---> 29\u001B[0m train_loader, valid_loader, test_loader \u001B[38;5;241m=\u001B[39m \u001B[43mget_data_loader\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(model, max_epochs, device, early_stop\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m     33\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;124;03m    Train model, store the best model, and run a final test.\u001B[39;00m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;124;03m    :param model: NN model used in the image classification\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;124;03m    :return: None\u001B[39;00m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/KIT/teaching/cogsys/kogsys_2022/hw6/yourID-yourName/ex1/data_loader.py:23\u001B[0m, in \u001B[0;36mget_data_loader\u001B[0;34m()\u001B[0m\n\u001B[1;32m     18\u001B[0m transform \u001B[38;5;241m=\u001B[39m transforms\u001B[38;5;241m.\u001B[39mCompose([transforms\u001B[38;5;241m.\u001B[39mToTensor(),\n\u001B[1;32m     19\u001B[0m                                 transforms\u001B[38;5;241m.\u001B[39mNormalize((\u001B[38;5;241m0.5\u001B[39m, \u001B[38;5;241m0.5\u001B[39m, \u001B[38;5;241m0.5\u001B[39m),\n\u001B[1;32m     20\u001B[0m                                                      (\u001B[38;5;241m0.5\u001B[39m, \u001B[38;5;241m0.5\u001B[39m, \u001B[38;5;241m0.5\u001B[39m))])\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# Load CIFAR-10 dataset\u001B[39;00m\n\u001B[0;32m---> 23\u001B[0m train_set \u001B[38;5;241m=\u001B[39m \u001B[43mtorchvision\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdatasets\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCIFAR10\u001B[49m\u001B[43m(\u001B[49m\u001B[43mroot\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m./data\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     24\u001B[0m \u001B[43m                                         \u001B[49m\u001B[43mdownload\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     25\u001B[0m train_set, valid_set \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mrandom_split(train_set, [\u001B[38;5;241m40000\u001B[39m,\n\u001B[1;32m     26\u001B[0m                                                                  \u001B[38;5;241m10000\u001B[39m])\n\u001B[1;32m     28\u001B[0m test_set \u001B[38;5;241m=\u001B[39m torchvision\u001B[38;5;241m.\u001B[39mdatasets\u001B[38;5;241m.\u001B[39mCIFAR10(root\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./data\u001B[39m\u001B[38;5;124m'\u001B[39m, train\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m     29\u001B[0m                                         download\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, transform\u001B[38;5;241m=\u001B[39mtransform)\n",
      "File \u001B[0;32m~/Documents/KIT/teaching/cogsys/ss22/code/venv/lib/python3.9/site-packages/torchvision/datasets/cifar.py:65\u001B[0m, in \u001B[0;36mCIFAR10.__init__\u001B[0;34m(self, root, train, transform, target_transform, download)\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain \u001B[38;5;241m=\u001B[39m train  \u001B[38;5;66;03m# training set or test set\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m download:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdownload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     67\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_integrity():\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset not found or corrupted. You can use download=True to download it\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/KIT/teaching/cogsys/ss22/code/venv/lib/python3.9/site-packages/torchvision/datasets/cifar.py:141\u001B[0m, in \u001B[0;36mCIFAR10.download\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    139\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFiles already downloaded and verified\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    140\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m--> 141\u001B[0m \u001B[43mdownload_and_extract_archive\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mroot\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmd5\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtgz_md5\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/KIT/teaching/cogsys/ss22/code/venv/lib/python3.9/site-packages/torchvision/datasets/utils.py:446\u001B[0m, in \u001B[0;36mdownload_and_extract_archive\u001B[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001B[0m\n\u001B[1;32m    443\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m filename:\n\u001B[1;32m    444\u001B[0m     filename \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mbasename(url)\n\u001B[0;32m--> 446\u001B[0m \u001B[43mdownload_url\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdownload_root\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmd5\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    448\u001B[0m archive \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(download_root, filename)\n\u001B[1;32m    449\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExtracting \u001B[39m\u001B[38;5;132;01m{\u001B[39;00marchive\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mextract_root\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/KIT/teaching/cogsys/ss22/code/venv/lib/python3.9/site-packages/torchvision/datasets/utils.py:156\u001B[0m, in \u001B[0;36mdownload_url\u001B[0;34m(url, root, filename, md5, max_redirect_hops)\u001B[0m\n\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    155\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDownloading \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m url \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m to \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m fpath)\n\u001B[0;32m--> 156\u001B[0m     \u001B[43m_urlretrieve\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    157\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (urllib\u001B[38;5;241m.\u001B[39merror\u001B[38;5;241m.\u001B[39mURLError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[1;32m    158\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m url[:\u001B[38;5;241m5\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m~/Documents/KIT/teaching/cogsys/ss22/code/venv/lib/python3.9/site-packages/torchvision/datasets/utils.py:50\u001B[0m, in \u001B[0;36m_urlretrieve\u001B[0;34m(url, filename, chunk_size)\u001B[0m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_urlretrieve\u001B[39m(url: \u001B[38;5;28mstr\u001B[39m, filename: \u001B[38;5;28mstr\u001B[39m, chunk_size: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1024\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m32\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     49\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m urllib\u001B[38;5;241m.\u001B[39mrequest\u001B[38;5;241m.\u001B[39murlopen(urllib\u001B[38;5;241m.\u001B[39mrequest\u001B[38;5;241m.\u001B[39mRequest(url, headers\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUser-Agent\u001B[39m\u001B[38;5;124m\"\u001B[39m: USER_AGENT})) \u001B[38;5;28;01mas\u001B[39;00m response:\n\u001B[0;32m---> 50\u001B[0m         \u001B[43m_save_response_content\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43miter\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchunk_size\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43mb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlength\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlength\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/KIT/teaching/cogsys/ss22/code/venv/lib/python3.9/site-packages/torchvision/datasets/utils.py:39\u001B[0m, in \u001B[0;36m_save_response_content\u001B[0;34m(content, destination, length)\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_save_response_content\u001B[39m(\n\u001B[1;32m     34\u001B[0m     content: Iterator[\u001B[38;5;28mbytes\u001B[39m],\n\u001B[1;32m     35\u001B[0m     destination: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m     36\u001B[0m     length: Optional[\u001B[38;5;28mint\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     37\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     38\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(destination, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m fh, tqdm(total\u001B[38;5;241m=\u001B[39mlength) \u001B[38;5;28;01mas\u001B[39;00m pbar:\n\u001B[0;32m---> 39\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m content:\n\u001B[1;32m     40\u001B[0m             \u001B[38;5;66;03m# filter out keep-alive new chunks\u001B[39;00m\n\u001B[1;32m     41\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m chunk:\n\u001B[1;32m     42\u001B[0m                 \u001B[38;5;28;01mcontinue\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/KIT/teaching/cogsys/ss22/code/venv/lib/python3.9/site-packages/torchvision/datasets/utils.py:50\u001B[0m, in \u001B[0;36m_urlretrieve.<locals>.<lambda>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_urlretrieve\u001B[39m(url: \u001B[38;5;28mstr\u001B[39m, filename: \u001B[38;5;28mstr\u001B[39m, chunk_size: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1024\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m32\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     49\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m urllib\u001B[38;5;241m.\u001B[39mrequest\u001B[38;5;241m.\u001B[39murlopen(urllib\u001B[38;5;241m.\u001B[39mrequest\u001B[38;5;241m.\u001B[39mRequest(url, headers\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUser-Agent\u001B[39m\u001B[38;5;124m\"\u001B[39m: USER_AGENT})) \u001B[38;5;28;01mas\u001B[39;00m response:\n\u001B[0;32m---> 50\u001B[0m         _save_response_content(\u001B[38;5;28miter\u001B[39m(\u001B[38;5;28;01mlambda\u001B[39;00m: \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchunk_size\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m), filename, length\u001B[38;5;241m=\u001B[39mresponse\u001B[38;5;241m.\u001B[39mlength)\n",
      "File \u001B[0;32m/usr/local/Cellar/python@3.9/3.9.8/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py:463\u001B[0m, in \u001B[0;36mHTTPResponse.read\u001B[0;34m(self, amt)\u001B[0m\n\u001B[1;32m    460\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    461\u001B[0m     \u001B[38;5;66;03m# Amount is given, implement using readinto\u001B[39;00m\n\u001B[1;32m    462\u001B[0m     b \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mbytearray\u001B[39m(amt)\n\u001B[0;32m--> 463\u001B[0m     n \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadinto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    464\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mmemoryview\u001B[39m(b)[:n]\u001B[38;5;241m.\u001B[39mtobytes()\n\u001B[1;32m    465\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    466\u001B[0m     \u001B[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001B[39;00m\n\u001B[1;32m    467\u001B[0m     \u001B[38;5;66;03m# and self.chunked\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/Cellar/python@3.9/3.9.8/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py:507\u001B[0m, in \u001B[0;36mHTTPResponse.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    502\u001B[0m         b \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmemoryview\u001B[39m(b)[\u001B[38;5;241m0\u001B[39m:\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength]\n\u001B[1;32m    504\u001B[0m \u001B[38;5;66;03m# we do not use _safe_read() here because this may be a .will_close\u001B[39;00m\n\u001B[1;32m    505\u001B[0m \u001B[38;5;66;03m# connection, and the user is reading more bytes than will be provided\u001B[39;00m\n\u001B[1;32m    506\u001B[0m \u001B[38;5;66;03m# (for example, reading in 1k chunks)\u001B[39;00m\n\u001B[0;32m--> 507\u001B[0m n \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadinto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    508\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m n \u001B[38;5;129;01mand\u001B[39;00m b:\n\u001B[1;32m    509\u001B[0m     \u001B[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001B[39;00m\n\u001B[1;32m    510\u001B[0m     \u001B[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001B[39;00m\n\u001B[1;32m    511\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_close_conn()\n",
      "File \u001B[0;32m/usr/local/Cellar/python@3.9/3.9.8/Frameworks/Python.framework/Versions/3.9/lib/python3.9/socket.py:704\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    702\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    703\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 704\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    705\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[1;32m    706\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/Cellar/python@3.9/3.9.8/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ssl.py:1241\u001B[0m, in \u001B[0;36mSSLSocket.recv_into\u001B[0;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[1;32m   1237\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1238\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1239\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[1;32m   1240\u001B[0m           \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[0;32m-> 1241\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1242\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1243\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001B[0;32m/usr/local/Cellar/python@3.9/3.9.8/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ssl.py:1099\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[0;34m(self, len, buffer)\u001B[0m\n\u001B[1;32m   1097\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1098\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1099\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1100\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1101\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# DO NOT MODIFY THIS BLOCK\n",
    "# DO NOT MODIFY THIS BLOCK\n",
    "# DO NOT MODIFY THIS BLOCK\n",
    "\n",
    "# Import Python libs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from ex1.fit import fit\n",
    "\n",
    "# Fix random seed to make sure the result in your computer is reproducible\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Max training epochs\n",
    "max_epochs = 100\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Task a)\n",
    "- Read the implementation of fully connected layers classifier, then run the\n",
    "cell afterwards to train this classifier. The training result will be shown\n",
    "automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT MODIFY THIS BLOCK\n",
    "# DO NOT MODIFY THIS BLOCK\n",
    "# DO NOT MODIFY THIS BLOCK\n",
    "\n",
    "class FCLayersNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Image classifier using fully connected layers\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Model Constructor, Initialize all the layers to be used\n",
    "        \"\"\"\n",
    "        super(FCLayersNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(32 * 32 * 3, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 256)\n",
    "        self.fc3 = nn.Linear(256, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        This function defines the forward pass of this net model.\n",
    "        Once this function is defined, the gradient back-propagation can be\n",
    "        automatically computed by PyTorch.\n",
    "\n",
    "        :param x: input data of this model\n",
    "        :return: output data of this model\n",
    "        \"\"\"\n",
    "        # The original data is 3rd order tensor, we need to flatten it to 1st\n",
    "        # order tensor, as the input of the fully connected layer.\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        # The data pass through the fully connected layers one after another\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc4(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- Run next cell and see the training progress and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Run me\n",
    "%matplotlib inline\n",
    "fc_net = FCLayersNet().to(device)\n",
    "fit(fc_net, max_epochs, device, early_stop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Task b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- Write down the missing cells:<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - I: , II: , III: , IV: , V: , VI: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finish the implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: PLEASE FINISH THE IMPLEMENTATION IN THIS BLOCK\n",
    "# TODO: PLEASE FINISH THE IMPLEMENTATION IN THIS BLOCK\n",
    "# TODO: PLEASE FINISH THE IMPLEMENTATION IN THIS BLOCK\n",
    "\n",
    "class ConvLayersNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Image classifier using convolutional layers\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Model Constructor, Initialize all the layers to be used\n",
    "        \"\"\"\n",
    "        super(ConvLayersNet, self).__init__()\n",
    "        ########   Your code begins here   ########\n",
    "\n",
    "        ########   Your code ends here   ########\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        This function defines the forward pass of this net model.\n",
    "        Once this function is defined, the gradient back-propagation can be\n",
    "        automatically computed by PyTorch.\n",
    "\n",
    "        :param x: input data of this model\n",
    "        :return: output data of this model\n",
    "        \"\"\"\n",
    "        ########   Your code begins here   ########\n",
    "\n",
    "        ########   Your code ends here   ########\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- Run next cell and see the training progress and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run me\n",
    "%matplotlib inline\n",
    "conv_net = ConvLayersNet().to(device)\n",
    "fit(conv_net, max_epochs, device, early_stop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recall the knowledge in Cognitive system lecture, what kind of benefits can\n",
    "we expect when applying max-pooling layer in CNNs?<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write down the missing cells:<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - I: , II: , III: , IV: , V: , VI: , VII: , VIII: , IX: , X: , XI: , XII: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finish the implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: PLEASE FINISH THE IMPLEMENTATION IN THIS BLOCK\n",
    "# TODO: PLEASE FINISH THE IMPLEMENTATION IN THIS BLOCK\n",
    "# TODO: PLEASE FINISH THE IMPLEMENTATION IN THIS BLOCK\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Image classifier using CNNs with more channels.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Model Constructor, Initialize all the layers to be used\n",
    "        \"\"\"\n",
    "        super(CNN, self).__init__()\n",
    "        ########   Your code begins here   ########\n",
    "\n",
    "        ########   Your code ends here   ########\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        This function defines the forward pass of this net model.\n",
    "        Once this function is defined, the gradient back-propagation can be\n",
    "        automatically computed by PyTorch.\n",
    "\n",
    "        :param x: input data of this model\n",
    "        :return: output data of this model\n",
    "        \"\"\"\n",
    "        ########   Your code begins here   ########\n",
    "\n",
    "        ########   Your code ends here   ########\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- Run next cell and see the training progress and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run me\n",
    "%matplotlib inline\n",
    "cnn = CNN().to(device)\n",
    "fit(cnn, max_epochs, device, early_stop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write down the missing cells:<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - I: , II: , III: , IV: , V: , VI: , VII: , VIII: , IX: , X: , XI: , XII: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finish the implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: PLEASE FINISH THE IMPLEMENTATION IN THIS BLOCK\n",
    "# TODO: PLEASE FINISH THE IMPLEMENTATION IN THIS BLOCK\n",
    "# TODO: PLEASE FINISH THE IMPLEMENTATION IN THIS BLOCK\n",
    "\n",
    "class MiniResNetSimple(nn.Module):\n",
    "    \"\"\"\n",
    "    Image classifier using CNNs with small kernel size.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Model Constructor, Initialize all the layers to be used\n",
    "        \"\"\"\n",
    "        super(MiniResNetSimple, self).__init__()\n",
    "        ########   Your code begins here   ########\n",
    "\n",
    "        ########   Your code ends here   ########\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        This function defines the forward pass of this net model.\n",
    "        Once this function is defined, the gradient back-propagation can be\n",
    "        automatically computed by PyTorch.\n",
    "\n",
    "        :param x: input data of this model\n",
    "        :return: output data of this model\n",
    "        \"\"\"\n",
    "        ########   Your code begins here   ########\n",
    " \n",
    "        ########   Your code ends here   ########\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Run next cell and see the training progress and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run me\n",
    "%matplotlib inline\n",
    "resnet = MiniResNetSimple().to(device)\n",
    "fit(resnet, max_epochs, device, early_stop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write down the missing cells:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - I: , II: , III: , IV: , V: , VI: , VII: , VIII: , IX: , X: , XI: , XII:, XIII: , XIV:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finish the implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: PLEASE FINISH THE IMPLEMENTATION IN THIS BLOCK\n",
    "# TODO: PLEASE FINISH THE IMPLEMENTATION IN THIS BLOCK\n",
    "# TODO: PLEASE FINISH THE IMPLEMENTATION IN THIS BLOCK\n",
    "\n",
    "class MiniResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Image classifier using ResNets with increasing channel size.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Model Constructor, Initialize all the layers to be used\n",
    "        \"\"\"\n",
    "        super(MiniResNet, self).__init__()\n",
    "        ########   Your code begins here   ########\n",
    "\n",
    "        ########   Your code ends here   ########\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        This function defines the forward pass of this net model.\n",
    "        Once this function is defined, the gradient back-propagation can be\n",
    "        automatically computed by PyTorch.\n",
    "\n",
    "        :param x: input data of this model\n",
    "        :return: output data of this model\n",
    "        \"\"\"\n",
    "        ########   Your code begins here   ########\n",
    " \n",
    "        ########   Your code ends here   ########\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run me\n",
    "%matplotlib inline\n",
    "resnet2 = MiniResNet().to(device)\n",
    "fit(resnet2, max_epochs, device, early_stop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}